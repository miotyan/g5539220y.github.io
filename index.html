<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>M78星云档案库</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="M78星云档案库">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="M78星云档案库">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="M78星云档案库">
  
    <link rel="alternative" href="/atom.xml" title="M78星云档案库" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <section id="main">
  
    <article id="post-Spark-当启用了一个WordCount的时候，都发生了什么奇妙的事？" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/24/Spark-当启用了一个WordCount的时候，都发生了什么奇妙的事？/">Spark-当启用了一个WordCount的时候，都发生了什么奇妙的事？</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/24/Spark-当启用了一个WordCount的时候，都发生了什么奇妙的事？/" class="article-date">
  <time datetime="2018-02-24T14:58:00.000Z" itemprop="datePublished">2018-02-24</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="先用一句话搞定WordCount"><a href="#先用一句话搞定WordCount" class="headerlink" title="先用一句话搞定WordCount"></a>先用一句话搞定WordCount</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">sc.textFile(&quot;hdfs://haihan:9000/sparkTest/word.txt).flatmap(_.split(&quot; &quot;)).map((_,1)).reduceBykey(_+_).saveAsFile(hdfs://haihan:9000/sparkTest/out)</div></pre></td></tr></table></figure>
<hr>
<h3 id="在这其中产生的RDD"><a href="#在这其中产生的RDD" class="headerlink" title="在这其中产生的RDD"></a>在这其中产生的RDD</h3><ul>
<li><h3 id="textfile-产生了2个RDD-gt-HadoopRDD和MapPartitionsRDD"><a href="#textfile-产生了2个RDD-gt-HadoopRDD和MapPartitionsRDD" class="headerlink" title="textfile 产生了2个RDD -&gt; HadoopRDD和MapPartitionsRDD"></a>textfile 产生了2个RDD -&gt; HadoopRDD和MapPartitionsRDD</h3></li>
<li><h3 id="flatMap-产生1个RDD-gt-MapPartitionsRDD"><a href="#flatMap-产生1个RDD-gt-MapPartitionsRDD" class="headerlink" title="flatMap 产生1个RDD -&gt; MapPartitionsRDD"></a>flatMap 产生1个RDD -&gt; MapPartitionsRDD</h3></li>
<li><h3 id="map-产生1个RDD-gt-MapPartitionsRDD"><a href="#map-产生1个RDD-gt-MapPartitionsRDD" class="headerlink" title="map 产生1个RDD  -&gt; MapPartitionsRDD"></a>map 产生1个RDD  -&gt; MapPartitionsRDD</h3></li>
<li><h3 id="reduceByKey产生1个RDD-gt-shuffleRDD"><a href="#reduceByKey产生1个RDD-gt-shuffleRDD" class="headerlink" title="reduceByKey产生1个RDD -&gt; shuffleRDD"></a>reduceByKey产生1个RDD -&gt; shuffleRDD</h3></li>
</ul>
<hr>
<h3 id="在这其中Driver和它提交到的集群都发生了什么"><a href="#在这其中Driver和它提交到的集群都发生了什么" class="headerlink" title="在这其中Driver和它提交到的集群都发生了什么"></a>在这其中Driver和它提交到的集群都发生了什么</h3><ul>
<li><h3 id="sc（driver）提交任务并申请资源，master分配资源，worker启动进程Exector（子进程）"><a href="#sc（driver）提交任务并申请资源，master分配资源，worker启动进程Exector（子进程）" class="headerlink" title="sc（driver）提交任务并申请资源，master分配资源，worker启动进程Exector（子进程）"></a>sc（driver）提交任务并申请资源，master分配资源，worker启动进程Exector（子进程）</h3></li>
<li><h3 id="driver向Exector提交计算任务（stage）-driver监控执行进度（如果所有Exector都执行完毕只剩下一个Exector-那样driver会在其他节点再申请一个Exector-看这两个Exector谁快-并用快速执行完的结果）"><a href="#driver向Exector提交计算任务（stage）-driver监控执行进度（如果所有Exector都执行完毕只剩下一个Exector-那样driver会在其他节点再申请一个Exector-看这两个Exector谁快-并用快速执行完的结果）" class="headerlink" title="driver向Exector提交计算任务（stage） driver监控执行进度（如果所有Exector都执行完毕只剩下一个Exector 那样driver会在其他节点再申请一个Exector 看这两个Exector谁快 并用快速执行完的结果）"></a>driver向Exector提交计算任务（stage） driver监控执行进度（如果所有Exector都执行完毕只剩下一个Exector 那样driver会在其他节点再申请一个Exector 看这两个Exector谁快 并用快速执行完的结果）</h3></li>
<li><h3 id="此时worker与master互相心跳感应"><a href="#此时worker与master互相心跳感应" class="headerlink" title="此时worker与master互相心跳感应"></a>此时worker与master互相心跳感应</h3></li>
</ul>
<hr>
<h3 id="Driver是怎么把自己的任务提交到集群里面的"><a href="#Driver是怎么把自己的任务提交到集群里面的" class="headerlink" title="Driver是怎么把自己的任务提交到集群里面的"></a>Driver是怎么把自己的任务提交到集群里面的</h3><ul>
<li><h3 id="第一阶段build-opeartor-DAG：构建RDD，经过一些列操作，形成了一个DAG（有向无环图），Action才会形成DAG"><a href="#第一阶段build-opeartor-DAG：构建RDD，经过一些列操作，形成了一个DAG（有向无环图），Action才会形成DAG" class="headerlink" title="第一阶段build opeartor DAG：构建RDD，经过一些列操作，形成了一个DAG（有向无环图），Action才会形成DAG"></a>第一阶段build opeartor DAG：构建RDD，经过一些列操作，形成了一个DAG（有向无环图），Action才会形成DAG</h3></li>
<li><h3 id="第二阶段提交DAG给DAGScheduler-DAGScheduler负责把DAG图划分一个一个的stage然后再以TaskSet提交，stage本质是Task的一个集合-有几个分区就有几个Task，"><a href="#第二阶段提交DAG给DAGScheduler-DAGScheduler负责把DAG图划分一个一个的stage然后再以TaskSet提交，stage本质是Task的一个集合-有几个分区就有几个Task，" class="headerlink" title="第二阶段提交DAG给DAGScheduler:DAGScheduler负责把DAG图划分一个一个的stage然后再以TaskSet提交，stage本质是Task的一个集合,有几个分区就有几个Task，"></a>第二阶段提交DAG给DAGScheduler:DAGScheduler负责把DAG图划分一个一个的stage然后再以TaskSet提交，stage本质是Task的一个集合,有几个分区就有几个Task，</h3><pre><code>每个Task（pipeline）的操作是一样的并且串行的，只是数据不一样，Task和Task之间是并行的
</code></pre></li>
<li><h3 id="第三阶段TaskScheduler：TaskScheduler在收到上一步的TaskSet后，通过cluster-manager（master）决定在哪个Worker中启动Exector，然后dirver提交Task到Worker中的Exector，通过Work中的Exector来执行。"><a href="#第三阶段TaskScheduler：TaskScheduler在收到上一步的TaskSet后，通过cluster-manager（master）决定在哪个Worker中启动Exector，然后dirver提交Task到Worker中的Exector，通过Work中的Exector来执行。" class="headerlink" title="第三阶段TaskScheduler：TaskScheduler在收到上一步的TaskSet后，通过cluster manager（master）决定在哪个Worker中启动Exector，然后dirver提交Task到Worker中的Exector，通过Work中的Exector来执行。"></a>第三阶段TaskScheduler：TaskScheduler在收到上一步的TaskSet后，通过cluster manager（master）决定在哪个Worker中启动Exector，然后dirver提交Task到Worker中的Exector，通过Work中的Exector来执行。</h3><pre><code>（重试，TaskScheduler在提交Task时遇到问题会启动一个相同的任务来重试）
</code></pre></li>
<li><h3 id="第四阶段Worker：Worker启动线程执行Task-通过BlockManager管理分区。-stage划分：从窄依赖开始，当有宽依赖时就会划分一个stage，如果到最后一步没有其他的宽依赖了，则直接划分成一个Stage，一个Stage中要考虑包含多个前面RDD的计算结果-。"><a href="#第四阶段Worker：Worker启动线程执行Task-通过BlockManager管理分区。-stage划分：从窄依赖开始，当有宽依赖时就会划分一个stage，如果到最后一步没有其他的宽依赖了，则直接划分成一个Stage，一个Stage中要考虑包含多个前面RDD的计算结果-。" class="headerlink" title="第四阶段Worker：Worker启动线程执行Task,通过BlockManager管理分区。(stage划分：从窄依赖开始，当有宽依赖时就会划分一个stage，如果到最后一步没有其他的宽依赖了，则直接划分成一个Stage，一个Stage中要考虑包含多个前面RDD的计算结果)。"></a>第四阶段Worker：Worker启动线程执行Task,通过BlockManager管理分区。(stage划分：从窄依赖开始，当有宽依赖时就会划分一个stage，如果到最后一步没有其他的宽依赖了，则直接划分成一个Stage，一个Stage中要考虑包含多个前面RDD的计算结果)。</h3></li>
</ul>
<hr>
<h2 id="两个重要的概念"><a href="#两个重要的概念" class="headerlink" title="两个重要的概念"></a>两个重要的概念</h2><ul>
<li><h3 id="窄依赖：父（或者多个父）RDD的分区数据全给了一个子RDD-与其他的子RDD无关"><a href="#窄依赖：父（或者多个父）RDD的分区数据全给了一个子RDD-与其他的子RDD无关" class="headerlink" title="窄依赖：父（或者多个父）RDD的分区数据全给了一个子RDD 与其他的子RDD无关"></a>窄依赖：父（或者多个父）RDD的分区数据全给了一个子RDD 与其他的子RDD无关</h3></li>
<li><h3 id="宽依赖：父（或者多个父）RDD的分区数据给了多个子RDD"><a href="#宽依赖：父（或者多个父）RDD的分区数据给了多个子RDD" class="headerlink" title="宽依赖：父（或者多个父）RDD的分区数据给了多个子RDD"></a>宽依赖：父（或者多个父）RDD的分区数据给了多个子RDD</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">常见的宽依赖:reduceBykey、groupBy、join(特殊情况)</div></pre></td></tr></table></figure></li>
</ul>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-速度开始Spark之旅" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/24/速度开始Spark之旅/">速度开始Spark之旅</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/24/速度开始Spark之旅/" class="article-date">
  <time datetime="2018-02-24T14:00:00.000Z" itemprop="datePublished">2018-02-24</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="安装部署Spark"><a href="#安装部署Spark" class="headerlink" title="安装部署Spark"></a>安装部署Spark</h2><h3 id="下好包后。。。。"><a href="#下好包后。。。。" class="headerlink" title="下好包后。。。。"></a>下好包后。。。。</h3><h3 id="第一步：依旧老办法！tar-zxvf-文件名-C-地址"><a href="#第一步：依旧老办法！tar-zxvf-文件名-C-地址" class="headerlink" title="第一步：依旧老办法！tar -zxvf 文件名 -C 地址"></a>第一步：依旧老办法！tar -zxvf 文件名 -C 地址</h3><h3 id="第二步：apache的软件常规操作，修改配置文件spark-env-sh。这一看就是环境变量了-在文件的末尾加上如下"><a href="#第二步：apache的软件常规操作，修改配置文件spark-env-sh。这一看就是环境变量了-在文件的末尾加上如下" class="headerlink" title="第二步：apache的软件常规操作，修改配置文件spark-env.sh。这一看就是环境变量了.在文件的末尾加上如下"></a>第二步：apache的软件常规操作，修改配置文件spark-env.sh。这一看就是环境变量了.在文件的末尾加上如下</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">export JAVA_HOME=$&#123;JAVA_HOME&#125;   #JAVA_HOME的地址</div><div class="line">export SPARK_MASTER_IP=haihan   #master的地址 如果没配Host 一定要先配Host再直接打名</div><div class="line">export SPARK_MASTER_PORT=7077   #端口号</div></pre></td></tr></table></figure>
<h3 id="第三步-修改Slave文件-跟hadoop中那个配置datanode地址文件差不多-在该文件中添加子节点所在的位置"><a href="#第三步-修改Slave文件-跟hadoop中那个配置datanode地址文件差不多-在该文件中添加子节点所在的位置" class="headerlink" title="第三步: 修改Slave文件(跟hadoop中那个配置datanode地址文件差不多),在该文件中添加子节点所在的位置"></a>第三步: 修改Slave文件(跟hadoop中那个配置datanode地址文件差不多),在该文件中添加子节点所在的位置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">gy</div><div class="line">clone_gy</div></pre></td></tr></table></figure>
<h3 id="第四步-把配置好的Spark目录发送到Worker机器上"><a href="#第四步-把配置好的Spark目录发送到Worker机器上" class="headerlink" title="第四步: 把配置好的Spark目录发送到Worker机器上"></a>第四步: 把配置好的Spark目录发送到Worker机器上</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">scp -r spark-1.5.2-bin-hadoop2.6/ gy:/home/ghadoop/app</div></pre></td></tr></table></figure>
<h3 id="额外的：关于Spark的HA"><a href="#额外的：关于Spark的HA" class="headerlink" title="额外的：关于Spark的HA"></a>额外的：关于Spark的HA</h3><h4 id="配置好zookeeper的情况下，还是在spark-env-sh的文件里增加一条配置"><a href="#配置好zookeeper的情况下，还是在spark-env-sh的文件里增加一条配置" class="headerlink" title="配置好zookeeper的情况下，还是在spark-env.sh的文件里增加一条配置"></a>配置好zookeeper的情况下，还是在spark-env.sh的文件里增加一条配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">Export SPARK_DAEMON_JAVA_OPTS=&quot;-Dspark.deploy.recoveryMode=ZOOKEEPER </div><div class="line">-Dspark.deploy.zookeeper.url=zk1,zk2,zk3    </div><div class="line">-Dspark.deploy.zookeeper.dir=/spark&quot;</div></pre></td></tr></table></figure>
<h4 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明:"></a>使用说明:</h4><ol>
<li>在node1节点上修改slaves配置文件内容指定worker节点</li>
<li>在node1上执行sbin/start-all.sh脚本，然后在node2上执行sbin/start-master.sh启动第二个Master</li>
</ol>
<h2 id="开启Spark之旅"><a href="#开启Spark之旅" class="headerlink" title="开启Spark之旅"></a>开启Spark之旅</h2><h3 id="运行一下官网的蒙特卡罗求π"><a href="#运行一下官网的蒙特卡罗求π" class="headerlink" title="运行一下官网的蒙特卡罗求π"></a>运行一下官网的蒙特卡罗求π</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">./spark-1.5.2-bin-hadoop2.6/bin/spark-submit \   #提交jar命令脚本</div><div class="line">--class org.apache.spark.examples.SparkPi \      #mian方法</div><div class="line">--master spark://haihan:7077 \                   #master地址</div><div class="line">--executor-memory 1G \                           #设置内存</div><div class="line">--total-executor-cores 2 \                       #设置CPU核数</div><div class="line">/app/spark-1.5.2-bin-hadoop2.6/lib/spark-examples-1.5.2-hadoop2.6.0.jar \ #jar包位置</div><div class="line">100  #mian方法参数</div></pre></td></tr></table></figure>
<h3 id="运行一下shell工具"><a href="#运行一下shell工具" class="headerlink" title="运行一下shell工具"></a>运行一下shell工具</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">./spark-1.5.2-bin-hadoop2.6/bin/spark-shell \</div><div class="line">--master spark://haihan:7077 \</div><div class="line">--executor-memory 2g \</div><div class="line">--total-executor-cores 2</div></pre></td></tr></table></figure>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-storm内部通信方式，以及Disruptor到底是个啥" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/24/storm内部通信方式，以及Disruptor到底是个啥/">storm内部通信方式，以及Disruptor到底是个啥</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/24/storm内部通信方式，以及Disruptor到底是个啥/" class="article-date">
  <time datetime="2018-02-24T01:39:00.000Z" itemprop="datePublished">2018-02-24</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="在Storm的世界，"><a href="#在Storm的世界，" class="headerlink" title="在Storm的世界，"></a>在Storm的世界，</h2><h3 id="每个exector都有一个缓存队列"><a href="#每个exector都有一个缓存队列" class="headerlink" title="每个exector都有一个缓存队列"></a>每个exector都有一个缓存队列</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">exector---&gt;nextTuple、execute</div></pre></td></tr></table></figure>
<h2 id="每个worker都有一个输入的总管，输出的总管"><a href="#每个worker都有一个输入的总管，输出的总管" class="headerlink" title="每个worker都有一个输入的总管，输出的总管"></a>每个worker都有一个输入的总管，输出的总管</h2><h3 id="总管要位置socker连接"><a href="#总管要位置socker连接" class="headerlink" title="总管要位置socker连接"></a>总管要位置socker连接</h3><h3 id="输入：serverSicjer-ip-port-监听"><a href="#输入：serverSicjer-ip-port-监听" class="headerlink" title="输入：serverSicjer(ip,port)监听"></a>输入：serverSicjer(ip,port)监听</h3><h3 id="输出：Map存入ip地址和端口号，以便找到其他机器的worker"><a href="#输出：Map存入ip地址和端口号，以便找到其他机器的worker" class="headerlink" title="输出：Map存入ip地址和端口号，以便找到其他机器的worker"></a>输出：Map<ip+port,socket>存入ip地址和端口号，以便找到其他机器的worker</ip+port,socket></h3><h2 id="worker之间内部通信"><a href="#worker之间内部通信" class="headerlink" title="worker之间内部通信"></a>worker之间内部通信</h2><ul>
<li><h3 id="数据从serverscoket传输过来后进行数据分发，把这些数据按照的方式存入map中"><a href="#数据从serverscoket传输过来后进行数据分发，把这些数据按照的方式存入map中" class="headerlink" title="数据从serverscoket传输过来后进行数据分发，把这些数据按照的方式存入map中."></a>数据从serverscoket传输过来后进行数据分发，把这些数据按照<taskid,inconing队列>的方式存入map中.</taskid,inconing队列></h3></li>
<li><h3 id="这时bolt中的execute线程通过它自己的队列（Disruptor）在map中取数值到自己的队列，bolt处理后封装Tuple发送（给下游bolt）到一个对外缓冲区中，在缓冲区内里的各个tuple和要发出去的各个task一一对应（tuple1—task14、tuple2—task1-。。）"><a href="#这时bolt中的execute线程通过它自己的队列（Disruptor）在map中取数值到自己的队列，bolt处理后封装Tuple发送（给下游bolt）到一个对外缓冲区中，在缓冲区内里的各个tuple和要发出去的各个task一一对应（tuple1—task14、tuple2—task1-。。）" class="headerlink" title="这时bolt中的execute线程通过它自己的队列（Disruptor）在map中取数值到自己的队列，bolt处理后封装Tuple发送（给下游bolt）到一个对外缓冲区中，在缓冲区内里的各个tuple和要发出去的各个task一一对应（tuple1—task14、tuple2—task1.。。）"></a>这时bolt中的execute线程通过它自己的队列（Disruptor）在map中取数值到自己的队列，bolt处理后封装Tuple发送（给下游bolt）到一个对外缓冲区中，在缓冲区内里的各个tuple和要发出去的各个task一一对应（tuple1—task14、tuple2—task1.。。）</h3></li>
<li><h3 id="最后输出大总管根据这些task信息将这些tuple发送。"><a href="#最后输出大总管根据这些task信息将这些tuple发送。" class="headerlink" title="最后输出大总管根据这些task信息将这些tuple发送。"></a>最后输出大总管根据这些task信息将这些tuple发送。</h3></li>
</ul>
<hr>
<h3 id="Disruptor是一个有界队列，应用场景是生产者消费者模型。它没有锁，就没有竞争，这样速度就很快。所有访问者都记录自己的序号实现方式，并允许多个生产者消费者共享的数据模式。它的底层是一个数组（Ring-Buffer）。"><a href="#Disruptor是一个有界队列，应用场景是生产者消费者模型。它没有锁，就没有竞争，这样速度就很快。所有访问者都记录自己的序号实现方式，并允许多个生产者消费者共享的数据模式。它的底层是一个数组（Ring-Buffer）。" class="headerlink" title="Disruptor是一个有界队列，应用场景是生产者消费者模型。它没有锁，就没有竞争，这样速度就很快。所有访问者都记录自己的序号实现方式，并允许多个生产者消费者共享的数据模式。它的底层是一个数组（Ring Buffer）。"></a>Disruptor是一个有界队列，应用场景是生产者消费者模型。它没有锁，就没有竞争，这样速度就很快。所有访问者都记录自己的序号实现方式，并允许多个生产者消费者共享的数据模式。它的底层是一个数组（Ring Buffer）。</h3><h3 id="生产者生产数据在数组上逐个覆盖"><a href="#生产者生产数据在数组上逐个覆盖" class="headerlink" title="生产者生产数据在数组上逐个覆盖"></a>生产者生产数据在数组上逐个覆盖</h3><h3 id="消费者消费数据在数组上拿取数据"><a href="#消费者消费数据在数组上拿取数据" class="headerlink" title="消费者消费数据在数组上拿取数据"></a>消费者消费数据在数组上拿取数据</h3><h3 id="生产者在生产数据时要判断当前数据是否被消费再进行覆盖"><a href="#生产者在生产数据时要判断当前数据是否被消费再进行覆盖" class="headerlink" title="生产者在生产数据时要判断当前数据是否被消费再进行覆盖"></a>生产者在生产数据时要判断当前数据是否被消费再进行覆盖</h3><h3 id="生产者和消费者在队列之间都有一个序号管理器（Sequence），里面管理生产者或消费者的生产-消费的个数-以及在队列数组中对应的标号"><a href="#生产者和消费者在队列之间都有一个序号管理器（Sequence），里面管理生产者或消费者的生产-消费的个数-以及在队列数组中对应的标号" class="headerlink" title="生产者和消费者在队列之间都有一个序号管理器（Sequence），里面管理生产者或消费者的生产/消费的个数 以及在队列数组中对应的标号"></a>生产者和消费者在队列之间都有一个序号管理器（Sequence），里面管理生产者或消费者的生产/消费的个数 以及在队列数组中对应的标号</h3><h3 id="从而防止了-多个生产者或消费者之间的生产-消费冲突"><a href="#从而防止了-多个生产者或消费者之间的生产-消费冲突" class="headerlink" title="从而防止了 多个生产者或消费者之间的生产/消费冲突"></a>从而防止了 多个生产者或消费者之间的生产/消费冲突</h3><hr>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-Storm提交任务的细节" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/24/Storm提交任务的细节/">Storm提交任务的细节</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/24/Storm提交任务的细节/" class="article-date">
  <time datetime="2018-02-24T01:17:00.000Z" itemprop="datePublished">2018-02-24</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="——-用户（程序员）——–"><a href="#——-用户（程序员）——–" class="headerlink" title="——-用户（程序员）——–"></a>——-用户（程序员）——–</h2><hr>
<h3 id="1-客户端运行storm-nimbus时，调用storm的脚本，该脚本为每个命令编写一个方法，每个方法生成一条java命令（java-version-xxx-Classname-args）"><a href="#1-客户端运行storm-nimbus时，调用storm的脚本，该脚本为每个命令编写一个方法，每个方法生成一条java命令（java-version-xxx-Classname-args）" class="headerlink" title="1.客户端运行storm nimbus时，调用storm的脚本，该脚本为每个命令编写一个方法，每个方法生成一条java命令（java -version xxx.Classname -args）"></a>1.客户端运行storm nimbus时，调用storm的脚本，该脚本为每个命令编写一个方法，每个方法生成一条java命令（java -version xxx.Classname -args）</h3><hr>
<h2 id="——–nimbus——"><a href="#——–nimbus——" class="headerlink" title="——–nimbus——"></a>——–nimbus——</h2><hr>
<h3 id="2-nimbus启动之后，接受客户端提交任务-在自己写的jar包中主类中的"><a href="#2-nimbus启动之后，接受客户端提交任务-在自己写的jar包中主类中的" class="headerlink" title="2. nimbus启动之后，接受客户端提交任务,在自己写的jar包中主类中的:"></a>2. nimbus启动之后，接受客户端提交任务,在自己写的jar包中主类中的:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">StormSubmitter.submitTopology(&quot;GyTopo&quot;, conf, topol);</div></pre></td></tr></table></figure>
<h3 id="会启动jar中的main方法，main方法中会执行以下代码"><a href="#会启动jar中的main方法，main方法中会执行以下代码" class="headerlink" title="会启动jar中的main方法，main方法中会执行以下代码"></a>会启动jar中的main方法，main方法中会执行以下代码</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">topologyBuilder.createtopology();</div></pre></td></tr></table></figure>
<h5 id="会将程序员写的spout对象和bolt对象进行序列化。客户端会将用户的jar上传到niumbus物理节点-storm-workdir-nimbus-inbox目录下，改名为一个UUID文件名的jar。在nimbus的物理节点的-storm-workdir-nimbus-stormdist目录下，有当前正在运行的topology的jar包和配置文件、序列化对象文件。"><a href="#会将程序员写的spout对象和bolt对象进行序列化。客户端会将用户的jar上传到niumbus物理节点-storm-workdir-nimbus-inbox目录下，改名为一个UUID文件名的jar。在nimbus的物理节点的-storm-workdir-nimbus-stormdist目录下，有当前正在运行的topology的jar包和配置文件、序列化对象文件。" class="headerlink" title="会将程序员写的spout对象和bolt对象进行序列化。客户端会将用户的jar上传到niumbus物理节点 ~/storm/workdir/nimbus/inbox目录下，改名为一个UUID文件名的jar。在nimbus的物理节点的~/storm/workdir/nimbus/stormdist目录下，有当前正在运行的topology的jar包和配置文件、序列化对象文件。"></a>会将程序员写的spout对象和bolt对象进行序列化。客户端会将用户的jar上传到niumbus物理节点 ~/storm/workdir/nimbus/inbox目录下，改名为一个UUID文件名的jar。在nimbus的物理节点的~/storm/workdir/nimbus/stormdist目录下，有当前正在运行的topology的jar包和配置文件、序列化对象文件。</h5><h3 id="3-接受任务后，会将任务进行分配，分配会在产生一个assignment对象，该对象会保存到zookeeper中-storm-assignments，该目录只保存正在运行的Topology任务"><a href="#3-接受任务后，会将任务进行分配，分配会在产生一个assignment对象，该对象会保存到zookeeper中-storm-assignments，该目录只保存正在运行的Topology任务" class="headerlink" title="3. 接受任务后，会将任务进行分配，分配会在产生一个assignment对象，该对象会保存到zookeeper中/storm/assignments，该目录只保存正在运行的Topology任务"></a>3. 接受任务后，会将任务进行分配，分配会在产生一个assignment对象，该对象会保存到zookeeper中/storm/assignments，该目录只保存正在运行的Topology任务</h3><hr>
<h2 id="——-supervisor——"><a href="#——-supervisor——" class="headerlink" title="——-supervisor——-"></a>——-supervisor——-</h2><hr>
<h3 id="4-supervisor通过watch机制，感知到nimbus在zk上的的任务分配信息，从zk上拉取信息，分辨自己任务"><a href="#4-supervisor通过watch机制，感知到nimbus在zk上的的任务分配信息，从zk上拉取信息，分辨自己任务" class="headerlink" title="4. supervisor通过watch机制，感知到nimbus在zk上的的任务分配信息，从zk上拉取信息，分辨自己任务"></a>4. supervisor通过watch机制，感知到nimbus在zk上的的任务分配信息，从zk上拉取信息，分辨自己任务</h3><h3 id="5-supervisor根据自己任务信息，启动自己的worker，并分配一个端口"><a href="#5-supervisor根据自己任务信息，启动自己的worker，并分配一个端口" class="headerlink" title="5.supervisor根据自己任务信息，启动自己的worker，并分配一个端口"></a>5.supervisor根据自己任务信息，启动自己的worker，并分配一个端口</h3><h2 id="———worker——"><a href="#———worker——" class="headerlink" title="———worker——"></a>———worker——</h2><hr>
<h3 id="6-worker启动之后，连接zk。拉取任务"><a href="#6-worker启动之后，连接zk。拉取任务" class="headerlink" title="6.worker启动之后，连接zk。拉取任务"></a>6.worker启动之后，连接zk。拉取任务</h3><h3 id="7-worker根据任务类型，分别执行spout或者blot任务"><a href="#7-worker根据任务类型，分别执行spout或者blot任务" class="headerlink" title="7.worker根据任务类型，分别执行spout或者blot任务"></a>7.worker根据任务类型，分别执行spout或者blot任务</h3><h3 id="spout的生命周期是open、netTuple、outputFiles"><a href="#spout的生命周期是open、netTuple、outputFiles" class="headerlink" title="spout的生命周期是open、netTuple、outputFiles"></a>spout的生命周期是open、netTuple、outputFiles</h3><h3 id="bolt的生命周期是preoars、execute（tuple）、outputfiles"><a href="#bolt的生命周期是preoars、execute（tuple）、outputfiles" class="headerlink" title="bolt的生命周期是preoars、execute（tuple）、outputfiles"></a>bolt的生命周期是preoars、execute（tuple）、outputfiles</h3>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-突然发现kafka的几个小细节" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/23/突然发现kafka的几个小细节/">突然发现kafka的几个小细节</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/23/突然发现kafka的几个小细节/" class="article-date">
  <time datetime="2018-02-23T13:56:00.000Z" itemprop="datePublished">2018-02-23</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-kafka生产数据时的分组策略"><a href="#1-kafka生产数据时的分组策略" class="headerlink" title="1.  kafka生产数据时的分组策略"></a>1.  kafka生产数据时的分组策略</h2><pre><code>默认是defaultPartition Utils.abs(key.hashCode)%numPartitions
key是在发送数据时传入的（proder.send（Keyedmessage（topic，myPartionKey，messAge））），
</code></pre><h2 id="2-kafka如何保证数据的完全生产"><a href="#2-kafka如何保证数据的完全生产" class="headerlink" title="2. kafka如何保证数据的完全生产"></a>2. kafka如何保证数据的完全生产</h2><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">  ack机制，broker表示发来的数据已确认无误，表示数据已保存内存或磁盘</div><div class="line"> 0 不等待block返回确认消息 </div><div class="line">-1 等待topic中的某个 partition leader保存成功的状态反馈</div><div class="line"> 1 等待topic中的某个 partition 所有副本都保存成功的反馈</div></pre></td></tr></table></figure>
</code></pre><h2 id="3-broker如何保存数据"><a href="#3-broker如何保存数据" class="headerlink" title="3. broker如何保存数据"></a>3. broker如何保存数据</h2><h3 id="在理论环境下，-broker-按照顺序读写的机制，可以每秒保存600M的数据（PageCache机制：PageCache本质就是把尽可能多的空闲内存当磁盘缓存来用）当前topic所属的broker上，必定有一个该topic的-partition-，-partition是一个磁盘目录中有多个segment集合（index，log）"><a href="#在理论环境下，-broker-按照顺序读写的机制，可以每秒保存600M的数据（PageCache机制：PageCache本质就是把尽可能多的空闲内存当磁盘缓存来用）当前topic所属的broker上，必定有一个该topic的-partition-，-partition是一个磁盘目录中有多个segment集合（index，log）" class="headerlink" title="在理论环境下， broker 按照顺序读写的机制，可以每秒保存600M的数据（PageCache机制：PageCache本质就是把尽可能多的空闲内存当磁盘缓存来用）当前topic所属的broker上，必定有一个该topic的 partition ， partition是一个磁盘目录中有多个segment集合（index，log）"></a>在理论环境下， broker 按照顺序读写的机制，可以每秒保存600M的数据（PageCache机制：PageCache本质就是把尽可能多的空闲内存当磁盘缓存来用）当前topic所属的broker上，必定有一个该topic的 partition ， partition是一个磁盘目录中有多个segment集合（index，log）</h3><h2 id="4-consumer和partition之间如何做负载均衡"><a href="#4-consumer和partition之间如何做负载均衡" class="headerlink" title="4. consumer和partition之间如何做负载均衡"></a>4. consumer和partition之间如何做负载均衡</h2><p>  ###最好是一一对应， 一个 partition 对应一个 consumer 如果consumer的数量过多，就会产生空闲的consumer<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">算法：</div><div class="line">有topic1, partitions :p0,p1,p2,p3</div><div class="line">加入group中，有如下consumer:c1,c2</div><div class="line">首先根据partition索引号对 partitions排序和根据 consumer.id排序</div><div class="line">计算倍数：M = [p0,p1,p2,p3].size/[c1,c2].size 结果值</div><div class="line">然后依次分配 partitions：c1 = [p0,p1],c2=[p2,p3] 即Ci = [p(i*M),p((i+1)*M-1)]</div></pre></td></tr></table></figure></p>
<h2 id="5-如何保证kafka消费者消费数据时全局有序的"><a href="#5-如何保证kafka消费者消费数据时全局有序的" class="headerlink" title="5. 如何保证kafka消费者消费数据时全局有序的"></a>5. 如何保证kafka消费者消费数据时全局有序的</h2><h3 id="保证不了，因为如果要全局有序，必须保证生产有序，存储有序，消费有序。有序，生产做集群，存储分片，消费设置为一个consumerGroup，要保证全局有序，就需要保证每个环节都有序只有一种可能就是只有一个-生产者-和-一个-partition-一个消费者。这种场景和大数据相悖。"><a href="#保证不了，因为如果要全局有序，必须保证生产有序，存储有序，消费有序。有序，生产做集群，存储分片，消费设置为一个consumerGroup，要保证全局有序，就需要保证每个环节都有序只有一种可能就是只有一个-生产者-和-一个-partition-一个消费者。这种场景和大数据相悖。" class="headerlink" title="保证不了，因为如果要全局有序，必须保证生产有序，存储有序，消费有序。有序，生产做集群，存储分片，消费设置为一个consumerGroup，要保证全局有序，就需要保证每个环节都有序只有一种可能就是只有一个 生产者 和 一个 partition , 一个消费者。这种场景和大数据相悖。"></a>保证不了，因为如果要全局有序，必须保证生产有序，存储有序，消费有序。有序，生产做集群，存储分片，消费设置为一个consumerGroup，要保证全局有序，就需要保证每个环节都有序只有一种可能就是只有一个 生产者 和 一个 partition , 一个消费者。这种场景和大数据相悖。</h3>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-kafka理解和安装" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/22/kafka理解和安装/">kafka理解和安装</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/22/kafka理解和安装/" class="article-date">
  <time datetime="2018-02-22T14:39:00.000Z" itemprop="datePublished">2018-02-22</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="kafka是一个缓存数据的系统。"><a href="#kafka是一个缓存数据的系统。" class="headerlink" title="kafka是一个缓存数据的系统。"></a>kafka是一个缓存数据的系统。</h1><h2 id="Storm、Sparkstreaming用过消费（获取）kafka的数据进行计算"><a href="#Storm、Sparkstreaming用过消费（获取）kafka的数据进行计算" class="headerlink" title="(Storm、Sparkstreaming用过消费（获取）kafka的数据进行计算)"></a>(Storm、Sparkstreaming用过消费（获取）kafka的数据进行计算)</h2><h3 id="kafka是一个分布式的消息缓存系统。由Scala写成。"><a href="#kafka是一个分布式的消息缓存系统。由Scala写成。" class="headerlink" title="kafka是一个分布式的消息缓存系统。由Scala写成。"></a>kafka是一个分布式的消息缓存系统。由Scala写成。</h3><h3 id="一个生产者消费者模型。类似与JMS的特性"><a href="#一个生产者消费者模型。类似与JMS的特性" class="headerlink" title="一个生产者消费者模型。类似与JMS的特性"></a>一个生产者消费者模型。类似与JMS的特性</h3><hr>
<h1 id="kafka基本理解"><a href="#kafka基本理解" class="headerlink" title="kafka基本理解"></a>kafka基本理解</h1><ol>
<li>类JMS（把点对点和发布订阅模式结合了）消费者可以多个，并且主动拉取数据。</li>
<li>数据生产者messageProducer：只负责数据生产，生产者的代码可以集成到任何系统中。<pre><code>数据分发策略由producer决定。默认是defaultPartition Utils.abs(key.hashCode)%numPartitions
</code></pre></li>
<li><p>数据消费者messageConsumer（增加MessageGroup）：可以有多个。每个consumer消费的数据都是一样的。consumer的组（consumerGroup），可以把多个consumer线程划分一个组，组里面的所有成员共同消费一个topic数据，组员之间不重复消费</p>
</li>
<li><p>数据的分类，主题：topic、destination（消息发送的目的地。本质Queue）<br>topic：目标发送的目的地。这是一个逻辑概念。落到磁盘上是一个partition目录。partition的目录中有多个segment组合（index，log），一个topic对应多个partition。一个partition对应多个segment组合。一个segment默认1G。</p>
<pre><code>每个parttiion可以设置多个副本（参数：--replication-factor 副本数）,所有的读写操作都是通过选举出一个leader来进行的。和mysql有区别，mesql做主从是读写分离。kafka中读写都是leader
</code></pre></li>
<li>broker（中间人）：管理保存数据的进程，只管数据存储，不管是谁生产，是谁消费。在集群中必须有个blockid</li>
<li>数据的分片分组：Partition，有多个，不同机器上有不同的机器的副本。数据生产到集群中的那一个parttion由生产者决定（Key的Hash算法）<br>每个parttiion是一个大文件 切割成小文件存在集群中</li>
</ol>
<p>一个组中的数据最好和分片数对应，一个分片对应一个组中的消费成员<br>如果组中的成员太多，必然会有成员空闲。</p>
<h2 id="partition数量和broker数量关系"><a href="#partition数量和broker数量关系" class="headerlink" title="partition数量和broker数量关系"></a>partition数量和broker数量关系</h2><h3 id="每个parttion数据如何保存到硬盘"><a href="#每个parttion数据如何保存到硬盘" class="headerlink" title="每个parttion数据如何保存到硬盘"></a>每个parttion数据如何保存到硬盘</h3><h3 id="面试题-如何保证消费者消费的数据是有序的"><a href="#面试题-如何保证消费者消费的数据是有序的" class="headerlink" title="面试题:如何保证消费者消费的数据是有序的"></a>面试题:如何保证消费者消费的数据是有序的</h3><ol>
<li>生产者集群模式有序号管理器</li>
<li>blocker端只设置一个partition</li>
<li>consumer如果是一个组，如何保证消费者有序—&gt;消费者线程里自定义一个数据结构来排序<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">一个partition的数据是间断性有序的，不连续</div><div class="line">针对一个tipic里的数据，只能做到partition内部有序，不能做到全局有序</div><div class="line">只有一种情况---&gt; 就是只有一个partition</div><div class="line">考虑kafka并发下的负载均衡</div></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="Kafka集群结构"><a href="#Kafka集群结构" class="headerlink" title="Kafka集群结构"></a>Kafka集群结构</h3><ol>
<li>kafka集群的服务器都叫broker。kafka有两类客户端（messageProducer、messageConsumer)</li>
<li>客户端和服务器之间采用TCP服务器连接</li>
<li>kafka中不同的业务的消息通过topic进行区分。而且每一个消息topic都会被分区，以分担消息读写的负载</li>
<li>每一个分区都可以有多个副本，以防止数据的丢失。每一个分区中的数据如果需要更新都必须通过该分区所有副本中的leader来更新！</li>
</ol>
<h3 id="Kafka在消费者中标记信息"><a href="#Kafka在消费者中标记信息" class="headerlink" title="Kafka在消费者中标记信息"></a>Kafka在消费者中标记信息</h3><p>kafka消费者在集群中分组，</p>
<ul>
<li><p>比如两个消费者共同消费一个topic：order_info，A和B所消费的消息不会重复<br>比如 order_inf中有100条消息，每个消息id，编号从0-99 消费者A消费0-49 消费者B就消耗50-99</p>
</li>
<li><p>消费者在具体消费某个topic中的消息时，可以指定起始偏移量</p>
</li>
<li><p>消息的格式可以是javabean、json、xml</p>
</li>
</ul>
<h1 id="kafka安装"><a href="#kafka安装" class="headerlink" title="kafka安装"></a>kafka安装</h1><h2 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h2><ol>
<li>解压</li>
<li><p>修改server.properties</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">broker.id=1</div><div class="line">log.dirs=&#123;日志目录&#125;</div><div class="line">zookeeper.connect=weekend05:2181,weekend06:2181,weekend07:2181</div></pre></td></tr></table></figure>
</li>
<li><p>将zookeeper集群启动</p>
</li>
<li><p>在每一台节点上启动broker<br>bin/kafka-server-start.sh config/server.properties</p>
</li>
<li><p>在kafka集群中创建一个topic<br>bin/kafka-topics.sh –create –zookeeper haihan:2181 –replication-factor 3 –partitions 1 –topic gy_noTopic</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --create --zookeeper haihan:2181  //zookeeper地址 </div><div class="line">--replication-factor 3  //副本数量为3  </div><div class="line">--partitions 1          //分区数   </div><div class="line">--topic gy_noTopic      //话题名</div></pre></td></tr></table></figure>
</li>
<li><p>用一个producer向某一个topic中写入消息 bin/kafka-console-producer.sh –broker-list haihan:9092 –topic gy_noTopic</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bin/kafka-console-producer.sh --broker-list haihan:9092  //broker地址 </div><div class="line">--topic gy_noTopic   //话题名</div></pre></td></tr></table></figure>
<p>7.用一个comsumer从某一个topic中读取信息<br>bin/kafka-console-consumer.sh –zookeeper haihan:2181 –from-beginning –topic gy_noTopic</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bin/kafka-console-consumer.sh --zookeeper haihan:2181 //zookeeper地址</div><div class="line">--from-beginning    //是否显示历史消息</div><div class="line">--topic gy_noTopic     //话题名</div></pre></td></tr></table></figure>
<p>8.查看一个topic的分区及副本状态信息<br>bin/kafka-topics.sh –describe –zookeeper haihan:2181 –topic order<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bin/kafka-topics.sh --describe --zookeeper haihan:2181 //zookeeper地址</div><div class="line">--topic gy_noTopic      //话题名</div></pre></td></tr></table></figure></p>
<h4 id="消息含义-Replicas-副本在集群的broker-id、leader-副本在集群中的leader（通过选举）、Isr-同步状态"><a href="#消息含义-Replicas-副本在集群的broker-id、leader-副本在集群中的leader（通过选举）、Isr-同步状态" class="headerlink" title="消息含义:Replicas 副本在集群的broker.id、leader 副本在集群中的leader（通过选举）、Isr 同步状态"></a>消息含义:Replicas 副本在集群的broker.id、leader 副本在集群中的leader（通过选举）、Isr 同步状态</h4><ol>
<li>查看已创建话题<br>bin/kafka-topics.sh –list –zookeeper haihan:2181</li>
</ol>
<h3 id="面试题警告！"><a href="#面试题警告！" class="headerlink" title="面试题警告！"></a>面试题警告！</h3><h4 id="kafka消费者读操作为什么快"><a href="#kafka消费者读操作为什么快" class="headerlink" title="kafka消费者读操作为什么快"></a>kafka消费者读操作为什么快</h4><p>消费者先从PageCache（内存）中查找，如果发生缺页才进行磁盘查找</p>
<p>最终返回实际数据，PageCache本质就是把尽可能多的空闲内存当磁盘缓存来用。</p>
<p>在JVM中的缓存是当前进行的缓存</p>
<p>使用PageCache功能避免在JVM内存缓存，JVM有强大的GC能力，如果数据进行多次GC后放到持久里就会出现不必要的问题<br>PageCache只是第一步。。进一步Sendfile服务，在硬盘中直接到网卡 不经过应用</p>
<h4 id="总结出来主要原因："><a href="#总结出来主要原因：" class="headerlink" title="总结出来主要原因："></a>总结出来主要原因：</h4><p>1.大量使用内存（PageCache）<br>2.发送数据不走应用（Sendfile）</p>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-极速安装Storm" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/20/极速安装Storm/">极速安装Storm</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/20/极速安装Storm/" class="article-date">
  <time datetime="2018-02-20T09:00:00.000Z" itemprop="datePublished">2018-02-20</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="重要！！！！-安装storm需要先安装zookeeper"><a href="#重要！！！！-安装storm需要先安装zookeeper" class="headerlink" title="(重要！！！！)安装storm需要先安装zookeeper"></a>(重要！！！！)安装storm需要先安装zookeeper</h2><h3 id="解压后进入conf-gt-修改storm-yaml"><a href="#解压后进入conf-gt-修改storm-yaml" class="headerlink" title="解压后进入conf-&gt;修改storm.yaml"></a>解压后进入conf-&gt;修改storm.yaml</h3><h2 id="必要内容"><a href="#必要内容" class="headerlink" title="必要内容"></a>必要内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">#zookeeper的服务节点</div><div class="line">storm.zookeeper.servers:</div><div class="line">    - &quot;haihan&quot;</div><div class="line">    - &quot;gy&quot;</div><div class="line">    - &quot;clone_gy&quot;</div><div class="line">#nimbus的地址</div><div class="line">nimbus.host: &quot;haihan&quot;</div></pre></td></tr></table></figure>
<hr>
<h2 id="次要内容"><a href="#次要内容" class="headerlink" title="次要内容"></a>次要内容</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">#指定supervisor节点上，启动worker时对应的端口号，每个端口对应槽，每个槽位对应一个worker。</div><div class="line">supervisor.slots.ports:</div><div class="line">    - 6700</div><div class="line">    - 6701</div><div class="line">    - 6702</div><div class="line">    - 6703</div><div class="line">#指定nimbus启动JVM最大可用内存大小</div><div class="line">nimbus.childopts: &quot;-Xmx1024m&quot;</div><div class="line">#指定supervisor启动JVM最大可用内存大小</div><div class="line">supervisor.childopts: &quot;-Xmx1024m&quot;</div><div class="line">#指定supervisor节点上，每个worker启动JVM最大可用内存大小</div><div class="line">worker.childopts: &quot;-Xmx768m&quot;</div><div class="line">#指定ui启动JVM最大可用内存大小，ui服务一般与nimbus同在一个节点上。</div><div class="line">ui.childopts: &quot;-Xmx768m&quot;</div></pre></td></tr></table></figure>
<h2 id="开始Storm之旅"><a href="#开始Storm之旅" class="headerlink" title="开始Storm之旅"></a>开始Storm之旅</h2><h3 id="启动为后台…master中启动nimbus和ui"><a href="#启动为后台…master中启动nimbus和ui" class="headerlink" title="启动为后台…master中启动nimbus和ui:"></a>启动为后台…master中启动nimbus和ui:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">nohup storm nimbus &amp;</div><div class="line">nohup storm ui &amp;</div></pre></td></tr></table></figure>
<p>###supervis机器上启动:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">nohup storm supervisor &amp;</div></pre></td></tr></table></figure></p>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-极速上手flume" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/12/极速上手flume/">极速上手flume</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/12/极速上手flume/" class="article-date">
  <time datetime="2018-02-12T06:25:00.000Z" itemprop="datePublished">2018-02-12</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="flume是一个日志采集框架，主要功能收集日志、聚合、传输"><a href="#flume是一个日志采集框架，主要功能收集日志、聚合、传输" class="headerlink" title="flume是一个日志采集框架，主要功能收集日志、聚合、传输"></a>flume是一个日志采集框架，主要功能收集日志、聚合、传输</h3><h3 id="flume可以采集很多形式的源数据、输出到HDFS、HBASE、kafka"><a href="#flume可以采集很多形式的源数据、输出到HDFS、HBASE、kafka" class="headerlink" title="flume可以采集很多形式的源数据、输出到HDFS、HBASE、kafka"></a>flume可以采集很多形式的源数据、输出到HDFS、HBASE、kafka</h3><h2 id="几个重要概念"><a href="#几个重要概念" class="headerlink" title="几个重要概念"></a>几个重要概念</h2><h3 id="Agent：flume的一个采集器进程、内部有三个组件：Source、Sink、Channel"><a href="#Agent：flume的一个采集器进程、内部有三个组件：Source、Sink、Channel" class="headerlink" title="Agent：flume的一个采集器进程、内部有三个组件：Source、Sink、Channel"></a>Agent：flume的一个采集器进程、内部有三个组件：Source、Sink、Channel</h3><hr>
<h4 id="Source：和采集源对接，获取数据"><a href="#Source：和采集源对接，获取数据" class="headerlink" title="Source：和采集源对接，获取数据"></a>Source：和采集源对接，获取数据</h4><h4 id="Sink-下沉地。采集数据传输到下一级agent或者最终存储系统"><a href="#Sink-下沉地。采集数据传输到下一级agent或者最终存储系统" class="headerlink" title="Sink:下沉地。采集数据传输到下一级agent或者最终存储系统"></a>Sink:下沉地。采集数据传输到下一级agent或者最终存储系统</h4><h4 id="Channel-Source和sink的传输通道"><a href="#Channel-Source和sink的传输通道" class="headerlink" title="Channel:Source和sink的传输通道"></a>Channel:Source和sink的传输通道</h4><hr>
<h3 id="flume中多个agent可以串联起来一起使用"><a href="#flume中多个agent可以串联起来一起使用" class="headerlink" title="flume中多个agent可以串联起来一起使用"></a>flume中多个agent可以串联起来一起使用</h3><h2 id="开启flume两种基本命令"><a href="#开启flume两种基本命令" class="headerlink" title="开启flume两种基本命令"></a>开启flume两种基本命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">./flume-ng agent --conf conf --conf-file ~/apps/flume/conf/netcat-logger.conf -n a1 -Dflume.root.logger=INFO,console </div><div class="line"></div><div class="line">./flume-ng agent 主要脚本</div><div class="line"></div><div class="line">--conf conf --conf-file 通过指定配置文件来启动flume</div><div class="line"></div><div class="line">~/apps/flume/conf/netcat-logger.conf 配置文件位置</div><div class="line"></div><div class="line">-n a1    指定agent名字</div><div class="line"></div><div class="line">-Dflume.root.logger=INFO,console 把结果输出到控制台</div></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bin/flume-ng agent -n $agent的名字 -c conf -f $配置文件地址</div></pre></td></tr></table></figure>
<h2 id="一个把目标文件夹里的文件采集到HDFS中的配置文件"><a href="#一个把目标文件夹里的文件采集到HDFS中的配置文件" class="headerlink" title="一个把目标文件夹里的文件采集到HDFS中的配置文件"></a>一个把目标文件夹里的文件采集到HDFS中的配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div></pre></td><td class="code"><pre><div class="line"># 定义这个agent中各组件的名字</div><div class="line">a1.sources = r1   #获取源数据组件名字</div><div class="line">a1.sinks = k1     #下沉输出组件名字</div><div class="line">a1.channels = c1  #传输组件名字</div><div class="line"></div><div class="line"># 描述和配置source组件：r1</div><div class="line">a1.sources.r1.type = spooldir   #描述获取源的操作</div><div class="line">a1.sources.r1.spoolDir = /home/ghadoop/gyflumes</div><div class="line">a1.sources.r1.fileHeader = true</div><div class="line"></div><div class="line"># 描述和配置sink组件：k1</div><div class="line">a1.sinks.k1.channel = c1    #定义传输组件名字</div><div class="line">a1.sinks.k1.type = hdfs     #描述下沉的位置</div><div class="line">a1.sinks.k1.hdfs.path = hdfs://haihan:9000/gy/%Y-%m-%d/%H    #定义日期和文件</div><div class="line">a1.sinks.k1.hdfs.fileType = DataStream</div><div class="line">a1.sinks.k1.hdfs.writeFormat=TEXT</div><div class="line">a1.sinks.k1.hdfs.filePrefix = flumeHdfs   #文件名头部</div><div class="line">a1.sinks.k1.hdfs.batchSize = 1000</div><div class="line">a1.sinks.k1.hdfs.rollSize = 10240</div><div class="line">a1.sinks.k1.hdfs.rollCount = 0</div><div class="line">a1.sinks.k1.hdfs.rollInterval = 1</div><div class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</div><div class="line"></div><div class="line"># 描述和配置channel组件，此处使用是内存缓存的方式</div><div class="line">a1.channels.c1.type = memory</div><div class="line">a1.channels.c1.capacity = 1000</div><div class="line">a1.channels.c1.transactionCapacity = 100</div><div class="line"></div><div class="line"># 描述和配置source  channel   sink之间的连接关系</div><div class="line">a1.sources.r1.channels = c1</div><div class="line">a1.sinks.k1.channel = c1</div></pre></td></tr></table></figure>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-scala 高级特型和隐式转换" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/11/scala 高级特型和隐式转换/">scala 高级特型和隐式转换</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/11/scala 高级特型和隐式转换/" class="article-date">
  <time datetime="2018-02-11T15:22:00.000Z" itemprop="datePublished">2018-02-11</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-高阶函数"><a href="#1-高阶函数" class="headerlink" title="1.高阶函数"></a>1.高阶函数</h2><h3 id="作为值的函数"><a href="#作为值的函数" class="headerlink" title="作为值的函数"></a>作为值的函数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">val func=(x: Int) =&gt; x*x</div><div class="line">arr=Array(1,2,3,4,5)</div><div class="line">arr.map(func)</div></pre></td></tr></table></figure>
<h4 id="方法也可以作为值传入方法中-此时隐式的将方法转换成了函数"><a href="#方法也可以作为值传入方法中-此时隐式的将方法转换成了函数" class="headerlink" title="方法也可以作为值传入方法中 此时隐式的将方法转换成了函数"></a>方法也可以作为值传入方法中 此时隐式的将方法转换成了函数</h4><h2 id="2-柯里化"><a href="#2-柯里化" class="headerlink" title="2.柯里化"></a>2.柯里化</h2><p>###可以接收多个参数，多个参数在多个括号里</p>
<p>###然后将原来接受两个参数的方法变成新的接受一个参数的方法的过程</p>
<h2 id="3-隐式转换-关键字：-implicit"><a href="#3-隐式转换-关键字：-implicit" class="headerlink" title="3.隐式转换 (关键字： implicit)"></a>3.隐式转换 (关键字： implicit)</h2><ul>
<li>定义在柯里化方法中的implicit修饰的变量</li>
<li>可以引用其他object中implicit修饰的变量</li>
<li>在调用其方法之前    import   里面有implicit修饰的object</li>
<li>含有implicit修饰的object，一定要写在调用其的object前面<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">object Value&#123;</div><div class="line">  implicit val name = &quot;haihan&quot;</div><div class="line">&#125;</div><div class="line">object implictDemo extends App &#123;</div><div class="line">    def say(a: Int)(implicit name: String = &quot;gy&quot;)=&#123;</div><div class="line">         println(s&quot;$name   $a&quot;)</div><div class="line">    &#125;</div><div class="line">  import Value.name</div><div class="line">  say(13)</div><div class="line">&#125;</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="3-scala的泛型表达方式"><a href="#3-scala的泛型表达方式" class="headerlink" title="3.scala的泛型表达方式"></a>3.scala的泛型表达方式</h2><h3 id="T-lt-上界"><a href="#T-lt-上界" class="headerlink" title="[T &lt;: 上界]"></a>[T &lt;: 上界]</h3><h3 id="T-gt-下界"><a href="#T-gt-下界" class="headerlink" title="[T &gt;: 下界]"></a>[T &gt;: 下界]</h3><h3 id="T-lt-视图定界-它必须传进去一个隐式转换的函数-相当于柯里化中的第二个括号中的隐式函数"><a href="#T-lt-视图定界-它必须传进去一个隐式转换的函数-相当于柯里化中的第二个括号中的隐式函数" class="headerlink" title="[T &lt;% 视图定界] 它必须传进去一个隐式转换的函数,相当于柯里化中的第二个括号中的隐式函数"></a>[T &lt;% 视图定界] 它必须传进去一个隐式转换的函数,相当于柯里化中的第二个括号中的隐式函数</h3><h3 id="T-上下文界定-它必须传一个隐式转换的值-相当于传一个变量-通过变量的类型来进行规则"><a href="#T-上下文界定-它必须传一个隐式转换的值-相当于传一个变量-通过变量的类型来进行规则" class="headerlink" title="[T : 上下文界定] 它必须传一个隐式转换的值,相当于传一个变量 通过变量的类型来进行规则"></a>[T : 上下文界定] 它必须传一个隐式转换的值,相当于传一个变量 通过变量的类型来进行规则</h3>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-对storm的理解和一些细节的说明" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/02/10/对storm的理解和一些细节的说明/">对storm的理解和一些细节的说明</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2018/02/10/对storm的理解和一些细节的说明/" class="article-date">
  <time datetime="2018-02-10T14:06:00.000Z" itemprop="datePublished">2018-02-10</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Storm的几个重要概念："><a href="#Storm的几个重要概念：" class="headerlink" title="Storm的几个重要概念："></a>Storm的几个重要概念：</h2><h3 id="1-Datasource：外部数据源"><a href="#1-Datasource：外部数据源" class="headerlink" title="1. Datasource：外部数据源"></a>1. Datasource：外部数据源</h3><h3 id="2-Spout：获取外部数据源，将外部数据源转化成storm内部数据，以Tuple为基本的传输单元发给Bolt"><a href="#2-Spout：获取外部数据源，将外部数据源转化成storm内部数据，以Tuple为基本的传输单元发给Bolt" class="headerlink" title="2. Spout：获取外部数据源，将外部数据源转化成storm内部数据，以Tuple为基本的传输单元发给Bolt"></a>2. Spout：获取外部数据源，将外部数据源转化成storm内部数据，以Tuple为基本的传输单元发给Bolt</h3><h3 id="3-Bolt：接收Spout-或上游的bolt发送的数据-发送的数据，进行业务逻辑处理节点。可以有多个。处理后发送给下一个bolt或者存储到某种介质（mysql、Redis）上"><a href="#3-Bolt：接收Spout-或上游的bolt发送的数据-发送的数据，进行业务逻辑处理节点。可以有多个。处理后发送给下一个bolt或者存储到某种介质（mysql、Redis）上" class="headerlink" title="3. Bolt：接收Spout(或上游的bolt发送的数据)发送的数据，进行业务逻辑处理节点。可以有多个。处理后发送给下一个bolt或者存储到某种介质（mysql、Redis）上"></a>3. Bolt：接收Spout(或上游的bolt发送的数据)发送的数据，进行业务逻辑处理节点。可以有多个。处理后发送给下一个bolt或者存储到某种介质（mysql、Redis）上</h3><h3 id="4-Tuple：一次消息传递的基本单元（一个对象，封装一个List）用来保存数据"><a href="#4-Tuple：一次消息传递的基本单元（一个对象，封装一个List）用来保存数据" class="headerlink" title="4. Tuple：一次消息传递的基本单元（一个对象，封装一个List）用来保存数据"></a>4. Tuple：一次消息传递的基本单元（一个对象，封装一个List）用来保存数据</h3><h3 id="5-StreamGrouping：数据分组策略（hadoop中的hashcode-num）Spout在给bolt发送Tuple时对Bolt有一个StreamGrouping，对Bolt进行分区"><a href="#5-StreamGrouping：数据分组策略（hadoop中的hashcode-num）Spout在给bolt发送Tuple时对Bolt有一个StreamGrouping，对Bolt进行分区" class="headerlink" title="5. StreamGrouping：数据分组策略（hadoop中的hashcode%num）Spout在给bolt发送Tuple时对Bolt有一个StreamGrouping，对Bolt进行分区"></a>5. StreamGrouping：数据分组策略（hadoop中的hashcode%num）Spout在给bolt发送Tuple时对Bolt有一个StreamGrouping，对Bolt进行分区</h3><hr>
<h2 id="常用几种StreamGrouping（一共七种）："><a href="#常用几种StreamGrouping（一共七种）：" class="headerlink" title="常用几种StreamGrouping（一共七种）："></a>常用几种StreamGrouping（一共七种）：</h2><h4 id="1-shuffle-Grouping：随机分组，随机发stream里面的Tuple给bolt，保证每个bolt里的tuple大致相同。这类分组方式的结果与Non-Grouping（不分组）类似-分组通过Random随机函数"><a href="#1-shuffle-Grouping：随机分组，随机发stream里面的Tuple给bolt，保证每个bolt里的tuple大致相同。这类分组方式的结果与Non-Grouping（不分组）类似-分组通过Random随机函数" class="headerlink" title="1. shuffle Grouping：随机分组，随机发stream里面的Tuple给bolt，保证每个bolt里的tuple大致相同。这类分组方式的结果与Non Grouping（不分组）类似 分组通过Random随机函数"></a>1. shuffle Grouping：随机分组，随机发stream里面的Tuple给bolt，保证每个bolt里的tuple大致相同。这类分组方式的结果与Non Grouping（不分组）类似 分组通过Random随机函数</h4><h4 id="2-Fields-Grouping：按照字段分组-按照id和其他type分组。同样的id进入到同样的bolt-hashcode-num"><a href="#2-Fields-Grouping：按照字段分组-按照id和其他type分组。同样的id进入到同样的bolt-hashcode-num" class="headerlink" title="2. Fields Grouping：按照字段分组 按照id和其他type分组。同样的id进入到同样的bolt   hashcode%num"></a>2. Fields Grouping：按照字段分组 按照id和其他type分组。同样的id进入到同样的bolt   hashcode%num</h4><h4 id="3-All-Grouping：把Tuple广播-所有bolt都会收到"><a href="#3-All-Grouping：把Tuple广播-所有bolt都会收到" class="headerlink" title="3. All Grouping：把Tuple广播 所有bolt都会收到"></a>3. All Grouping：把Tuple广播 所有bolt都会收到</h4><h4 id="4-Local-or-shuffle-Grouping：Spout优先把Tuple发给自己本地机器上的bolt（自己在本地发采用shuffle）-避免网络传输"><a href="#4-Local-or-shuffle-Grouping：Spout优先把Tuple发给自己本地机器上的bolt（自己在本地发采用shuffle）-避免网络传输" class="headerlink" title="4. Local or shuffle Grouping：Spout优先把Tuple发给自己本地机器上的bolt（自己在本地发采用shuffle） 避免网络传输"></a>4. Local or shuffle Grouping：Spout优先把Tuple发给自己本地机器上的bolt（自己在本地发采用shuffle） 避免网络传输</h4><hr>
<h2 id="并发度：用户指定的一种类型的任务（定义的Spout要干什么工作）被几个线程同时执行。并发度是多少就是线程的数量。一个任务的多个线程，会被运行在多个worker（JVM）上"><a href="#并发度：用户指定的一种类型的任务（定义的Spout要干什么工作）被几个线程同时执行。并发度是多少就是线程的数量。一个任务的多个线程，会被运行在多个worker（JVM）上" class="headerlink" title="并发度：用户指定的一种类型的任务（定义的Spout要干什么工作）被几个线程同时执行。并发度是多少就是线程的数量。一个任务的多个线程，会被运行在多个worker（JVM）上"></a>并发度：用户指定的一种类型的任务（定义的Spout要干什么工作）被几个线程同时执行。并发度是多少就是线程的数量。一个任务的多个线程，会被运行在多个worker（JVM）上</h2><hr>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">   有一种类似于平均算法的负载均衡策略。</div><div class="line">（尽可能减少网络IO传输和mr中程序的map方法</div><div class="line">尽量运行在数据所在节点的道理是一样的）</div></pre></td></tr></table></figure>
<h2 id="一个简单的Topology的工作流程"><a href="#一个简单的Topology的工作流程" class="headerlink" title="一个简单的Topology的工作流程"></a>一个简单的Topology的工作流程</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">Topology1：</div><div class="line">-&gt;Spout获取外部一条一条的数据（String、json、javabean）</div><div class="line">-&gt;Spout在内部发送给Bolt（bolt进行业务处理）</div><div class="line">-&gt;内部有好多bolt进行业务步骤1.。2.。。3.这些bolt平行处理</div><div class="line">-&gt;bolt处理后将结果数据保存到Redis</div></pre></td></tr></table></figure>
<h2 id="几个重要的点"><a href="#几个重要的点" class="headerlink" title="几个重要的点"></a>几个重要的点</h2><h3 id="1-一个storm可以获取多个数据源"><a href="#1-一个storm可以获取多个数据源" class="headerlink" title="1. 一个storm可以获取多个数据源"></a>1. 一个storm可以获取多个数据源</h3><h3 id="2-每个-Topology-之间不能共享数据"><a href="#2-每个-Topology-之间不能共享数据" class="headerlink" title="2. 每个 Topology 之间不能共享数据"></a>2. 每个 Topology 之间不能共享数据</h3><h3 id="3-一个-Topology的数据是自己独有的"><a href="#3-一个-Topology的数据是自己独有的" class="headerlink" title="3. 一个 Topology的数据是自己独有的"></a>3. 一个 Topology的数据是自己独有的</h3><h3 id="4-和其他-Topology没有关系"><a href="#4-和其他-Topology没有关系" class="headerlink" title="4. 和其他 Topology没有关系"></a>4. 和其他 Topology没有关系</h3><hr>
<h2 id="storm内部架构："><a href="#storm内部架构：" class="headerlink" title="storm内部架构："></a>storm内部架构：</h2><ul>
<li><h4 id="nimbus：任务分配，通过zookeeper和supervisor传送任务信息"><a href="#nimbus：任务分配，通过zookeeper和supervisor传送任务信息" class="headerlink" title="nimbus：任务分配，通过zookeeper和supervisor传送任务信息"></a>nimbus：任务分配，通过zookeeper和supervisor传送任务信息</h4></li>
<li><h4 id="supervisor：当前物理机上的管理，负责接收nimbus分配的任务，收到任务，启动worker"><a href="#supervisor：当前物理机上的管理，负责接收nimbus分配的任务，收到任务，启动worker" class="headerlink" title="supervisor：当前物理机上的管理，负责接收nimbus分配的任务，收到任务，启动worker"></a>supervisor：当前物理机上的管理，负责接收nimbus分配的任务，收到任务，启动worker</h4></li>
<li><h4 id="worker：执行具体任务的组件。任务类型：Spout、bolt。可以同时存在多个Spout、bolt任务。启动一个exector线程。其实就是一个JVM。"><a href="#worker：执行具体任务的组件。任务类型：Spout、bolt。可以同时存在多个Spout、bolt任务。启动一个exector线程。其实就是一个JVM。" class="headerlink" title="worker：执行具体任务的组件。任务类型：Spout、bolt。可以同时存在多个Spout、bolt任务。启动一个exector线程。其实就是一个JVM。"></a>worker：执行具体任务的组件。任务类型：Spout、bolt。可以同时存在多个Spout、bolt任务。启动一个exector线程。其实就是一个JVM。</h4></li>
<li><h4 id="Task（本质上是一个线程）：worker每一个Spout、bolt的线程成为一个task。每个Task属于某个组件并发度中的一个。strom0-8以后task的线程不与物理线程同步，即一个exector可以有多个Task。但在默认情况下：executor-thread-task"><a href="#Task（本质上是一个线程）：worker每一个Spout、bolt的线程成为一个task。每个Task属于某个组件并发度中的一个。strom0-8以后task的线程不与物理线程同步，即一个exector可以有多个Task。但在默认情况下：executor-thread-task" class="headerlink" title="Task（本质上是一个线程）：worker每一个Spout、bolt的线程成为一个task。每个Task属于某个组件并发度中的一个。strom0.8以后task的线程不与物理线程同步，即一个exector可以有多个Task。但在默认情况下：executor=thread=task"></a>Task（本质上是一个线程）：worker每一个Spout、bolt的线程成为一个task。每个Task属于某个组件并发度中的一个。strom0.8以后task的线程不与物理线程同步，即一个exector可以有多个Task。但在默认情况下：executor=thread=task</h4></li>
<li><h4 id="zookeeper：保存任务分配、心跳信息。"><a href="#zookeeper：保存任务分配、心跳信息。" class="headerlink" title="zookeeper：保存任务分配、心跳信息。"></a>zookeeper：保存任务分配、心跳信息。</h4></li>
<li><h4 id="一台物理机可以起多个worker-数量跟物理配置、端口号有关"><a href="#一台物理机可以起多个worker-数量跟物理配置、端口号有关" class="headerlink" title="一台物理机可以起多个worker 数量跟物理配置、端口号有关"></a>一台物理机可以起多个worker 数量跟物理配置、端口号有关</h4></li>
<li><h4 id="一个worker占用一个端口号"><a href="#一个worker占用一个端口号" class="headerlink" title="一个worker占用一个端口号"></a>一个worker占用一个端口号</h4></li>
</ul>
<h2 id="worker与topology"><a href="#worker与topology" class="headerlink" title="worker与topology"></a>worker与topology</h2><pre><code>一个worker只属于一个topology（和它共存亡）
一个topology要求的worker数量不足时，
集群在任务分配根据现有的worker数量先运行topology，
如果当前中的worker数量为0 
那么新提交的topology只会标识为active 不会运行。当有空闲的资源才运行
</code></pre><h2 id="storm也有两种运行模式：集群。本地（在当前ide中运行）"><a href="#storm也有两种运行模式：集群。本地（在当前ide中运行）" class="headerlink" title="storm也有两种运行模式：集群。本地（在当前ide中运行）"></a>storm也有两种运行模式：集群。本地（在当前ide中运行）</h2>
      

      
        
    </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  
</section>
        <aside id="sidebar">
  <nav class="menus">
  	<ul>
  		<li><a href="/"><i class="icon icon-home"></i></a></li>
  		
			<li><a href="/archives"><i class="icon icon-fenlei"></i></a></li>
  		
  		
			<li><a href="/tags"><i class="icon icon-tag"></i></a></li>
  		
  		
  			<li><a href="https://github.com/g5539220y" target="_blank"><i class="icon icon-github"></i></a></li>
  		
  	</ul>
  </nav>
  <a id="go-top" href="#"><i class="icon icon-up"></i></a>
</aside>

      </div>
      <footer id="footer">
  
	<div id="footer-info" class="inner">
	  &copy; 2018 圈 
	  - Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	  - Theme <a href="https://github.com/hejianxian/hexo-theme-jane/" target="_blank">Jane</a>
	</div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tag</a>
  
    <a href="https://github.com/g5539220y" class="mobile-nav-link">Github</a>
  
</nav>
    

<script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>