<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>M78星云档案库</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="M78星云档案库">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="M78星云档案库">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="M78星云档案库">
  
    <link rel="alternative" href="/atom.xml" title="M78星云档案库" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <div class="outer">
        <section id="main">
  
    <article id="post-拯救笔记----解决恼人的数据倾斜" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/15/拯救笔记----解决恼人的数据倾斜/">拯救笔记----解决恼人的数据倾斜</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/12/15/拯救笔记----解决恼人的数据倾斜/" class="article-date">
  <time datetime="2017-12-15T00:51:00.000Z" itemprop="datePublished">2017-12-15</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="数据倾斜：由于有的数据的特殊原因，在map阶段后有很大的一部分数据进入到同一个reduce里面，而导致其他reduce接收的数据少。从而产生了数据倾斜"><a href="#数据倾斜：由于有的数据的特殊原因，在map阶段后有很大的一部分数据进入到同一个reduce里面，而导致其他reduce接收的数据少。从而产生了数据倾斜" class="headerlink" title="数据倾斜：由于有的数据的特殊原因，在map阶段后有很大的一部分数据进入到同一个reduce里面，而导致其他reduce接收的数据少。从而产生了数据倾斜"></a>数据倾斜：由于有的数据的特殊原因，在map阶段后有很大的一部分数据进入到同一个reduce里面，而导致其他reduce接收的数据少。从而产生了数据倾斜</h2><h3 id="解决方法：尽量在map里面解决，利用map的分布式缓存，把需要处理的数据直接放在map里执行"><a href="#解决方法：尽量在map里面解决，利用map的分布式缓存，把需要处理的数据直接放在map里执行" class="headerlink" title="解决方法：尽量在map里面解决，利用map的分布式缓存，把需要处理的数据直接放在map里执行"></a>解决方法：尽量在map里面解决，利用map的分布式缓存，把需要处理的数据直接放在map里执行</h3><h2 id="实例：map里面的join操作"><a href="#实例：map里面的join操作" class="headerlink" title="实例：map里面的join操作"></a>实例：map里面的join操作</h2><h3 id="要想把文件加载到maptask中！必须知道的四条配置"><a href="#要想把文件加载到maptask中！必须知道的四条配置" class="headerlink" title="要想把文件加载到maptask中！必须知道的四条配置"></a>要想把文件加载到maptask中！必须知道的四条配置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">job.addArchiveToClassPath(archive);  缓存jar包到maptask运行节点的classpath中</div><div class="line">job.addFileToClassPath(file);        缓存文件到maptask运行节点的classpath中</div><div class="line">job.addCacheArchive(uri);            缓存压缩包到maptask运行节点的工作目录中</div><div class="line">job.addCacheFile(uri);               缓存普通文件到maptask运行节点的工作目录中</div></pre></td></tr></table></figure>
<h3 id="配置完这四条之后，就可以开始从mapper类里读它了。"><a href="#配置完这四条之后，就可以开始从mapper类里读它了。" class="headerlink" title="配置完这四条之后，就可以开始从mapper类里读它了。"></a>配置完这四条之后，就可以开始从mapper类里读它了。</h3><h3 id="mapper框架中有个setup方法，它是负责初始化一些数据，在map前执行，只执行一次，在这里通过setup方法把想拼的信息放进map里"><a href="#mapper框架中有个setup方法，它是负责初始化一些数据，在map前执行，只执行一次，在这里通过setup方法把想拼的信息放进map里" class="headerlink" title="mapper框架中有个setup方法，它是负责初始化一些数据，在map前执行，只执行一次，在这里通过setup方法把想拼的信息放进map里"></a>mapper框架中有个setup方法，它是负责初始化一些数据，在map前执行，只执行一次，在这里通过setup方法把想拼的信息放进map里</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">  Map&lt;String, String&gt; infomap = new HashMap&lt;String, String&gt;();</div><div class="line">@Override</div><div class="line">protected void setup(Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</div><div class="line">		throws IOException, InterruptedException &#123;</div><div class="line">	BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(&quot;market.txt&quot;)));</div><div class="line">    String line;</div><div class="line">	while(StringUtils.isNotEmpty(line=br.readLine()))</div><div class="line">    &#123;</div><div class="line">    	String[] fields=line.split(&quot;\t&quot;);</div><div class="line">    	String tempinfo = fields[0]+&quot;	&quot;+fields[1];</div><div class="line">    	infomap.put(fields[2],tempinfo); 		    	</div><div class="line">    &#125;</div><div class="line">	br.close();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="把信息表中需要拼接的数据先放在tempinfo里面，在通过一个拼接的共有字段来设置key，put到HashMap中-通过StringBuffer来读数据"><a href="#把信息表中需要拼接的数据先放在tempinfo里面，在通过一个拼接的共有字段来设置key，put到HashMap中-通过StringBuffer来读数据" class="headerlink" title="把信息表中需要拼接的数据先放在tempinfo里面，在通过一个拼接的共有字段来设置key，put到HashMap中(通过StringBuffer来读数据)"></a>把信息表中需要拼接的数据先放在tempinfo里面，在通过一个拼接的共有字段来设置key，put到HashMap中(通过StringBuffer来读数据)</h4><h3 id="然后到Map阶段正常切就行，把切出来的共有字段直接map-get出来，拼接输出就行，简单粗暴！"><a href="#然后到Map阶段正常切就行，把切出来的共有字段直接map-get出来，拼接输出就行，简单粗暴！" class="headerlink" title="然后到Map阶段正常切就行，把切出来的共有字段直接map.get出来，拼接输出就行，简单粗暴！"></a>然后到Map阶段正常切就行，把切出来的共有字段直接map.get出来，拼接输出就行，简单粗暴！</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">  protected void map(LongWritable key, Text value, Mapper&lt;LongWritable, Text, Text, NullWritable&gt;.Context context)</div><div class="line">		throws IOException, InterruptedException &#123;</div><div class="line">		Text k = new Text();</div><div class="line">	    String gunline = value.toString();</div><div class="line">	    String[] gun_fields=gunline.split(&quot;\t&quot;);</div><div class="line">	    String info = infomap.get(gun_fields[0]);</div><div class="line">	    k.set(gunline+&quot;	&quot;+info);</div><div class="line">	    context.write(k, NullWritable.get());			  			    </div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="警醒自己！！！！在所有工作都做完之后一定"><a href="#警醒自己！！！！在所有工作都做完之后一定" class="headerlink" title="警醒自己！！！！在所有工作都做完之后一定"></a>警醒自己！！！！在所有工作都做完之后一定</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">boolean res = job.waitForCompletion(true);</div><div class="line">System.exit(res?0:1);</div></pre></td></tr></table></figure>
<p>刚才怎么搞都运行不了 就是因为没写这句话！看来job内容不能复制了。越复制越傻，多写几遍为妙！</p>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-拯救笔记----Partition之电话号码归属地分类" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/14/拯救笔记----Partition之电话号码归属地分类/">拯救笔记----Partition之电话号码归属地分类</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/12/14/拯救笔记----Partition之电话号码归属地分类/" class="article-date">
  <time datetime="2017-12-14T13:05:00.000Z" itemprop="datePublished">2017-12-14</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="需求：接着上一个流量汇总排序的写，把电话号码分类归省"><a href="#需求：接着上一个流量汇总排序的写，把电话号码分类归省" class="headerlink" title="需求：接着上一个流量汇总排序的写，把电话号码分类归省"></a>需求：接着上一个流量汇总排序的写，把电话号码分类归省</h2><h3 id="原理：自定义partition。通过继承partition的类，来重写getPartition方法"><a href="#原理：自定义partition。通过继承partition的类，来重写getPartition方法" class="headerlink" title="原理：自定义partition。通过继承partition的类，来重写getPartition方法"></a>原理：自定义partition。通过继承partition的类，来重写getPartition方法</h3><h3 id="Partition：在map阶段的收集器到缓冲区排序后的一个分区组件，为maptask的数据分组从而发送到reduceTask"><a href="#Partition：在map阶段的收集器到缓冲区排序后的一个分区组件，为maptask的数据分组从而发送到reduceTask" class="headerlink" title="Partition：在map阶段的收集器到缓冲区排序后的一个分区组件，为maptask的数据分组从而发送到reduceTask"></a>Partition：在map阶段的收集器到缓冲区排序后的一个分区组件，为maptask的数据分组从而发送到reduceTask</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">public class ProvincePartitioner extends Partitioner&lt;flowbean,IntWritable&gt;&#123;</div><div class="line">    static HashMap&lt;String,Integer&gt; provinceMap =new HashMap&lt;String,Integer&gt;();</div><div class="line">    static &#123;</div><div class="line">        provinceMap.put(&quot;135&quot;, 0);</div><div class="line">    	provinceMap.put(&quot;136&quot;, 1);</div><div class="line">    	provinceMap.put(&quot;137&quot;, 2);</div><div class="line">    	provinceMap.put(&quot;138&quot;, 3);</div><div class="line">    	provinceMap.put(&quot;139&quot;, 4);</div><div class="line">    &#125;</div><div class="line"> </div><div class="line">	@Override</div><div class="line">	public int getPartition(flowbean k, IntWritable arg1, int arg2) &#123;</div><div class="line">		long str = k.getNum();</div><div class="line">		String numb = String.valueOf(str);</div><div class="line">		Integer res=provinceMap.get(numb.substring(0, 3));</div><div class="line">		return res==null?5:res;</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h3 id="差不多就这样！就是要通过什么特征分区搞进来，这个getPartition方法也有一个kv对是跟map的k-out和v-out对应的，毕竟是mapTask拉出来的东西嘛"><a href="#差不多就这样！就是要通过什么特征分区搞进来，这个getPartition方法也有一个kv对是跟map的k-out和v-out对应的，毕竟是mapTask拉出来的东西嘛" class="headerlink" title="差不多就这样！就是要通过什么特征分区搞进来，这个getPartition方法也有一个kv对是跟map的k-out和v-out对应的，毕竟是mapTask拉出来的东西嘛"></a>差不多就这样！就是要通过什么特征分区搞进来，这个getPartition方法也有一个kv对是跟map的k-out和v-out对应的，毕竟是mapTask拉出来的东西嘛</h3><h3 id="然后把想要区分的东西拿出来，搞个什么字典啊，数据库啊，做一个特征分析，最后得出一个分区格子。这里弄个HashMap，把对应的手机号分配到对应的几号区"><a href="#然后把想要区分的东西拿出来，搞个什么字典啊，数据库啊，做一个特征分析，最后得出一个分区格子。这里弄个HashMap，把对应的手机号分配到对应的几号区" class="headerlink" title="然后把想要区分的东西拿出来，搞个什么字典啊，数据库啊，做一个特征分析，最后得出一个分区格子。这里弄个HashMap，把对应的手机号分配到对应的几号区"></a>然后把想要区分的东西拿出来，搞个什么字典啊，数据库啊，做一个特征分析，最后得出一个分区格子。这里弄个HashMap，把对应的手机号分配到对应的几号区</h3><h3 id="需要注意的是-一定要考虑不满足条件的那个区，把那个区定到最后！！！！还有设置配置文件时候一定要把这个区多留出来，比如这个分5个区，多一个不和条件区，所以一共分6个区"><a href="#需要注意的是-一定要考虑不满足条件的那个区，把那个区定到最后！！！！还有设置配置文件时候一定要把这个区多留出来，比如这个分5个区，多一个不和条件区，所以一共分6个区" class="headerlink" title="需要注意的是 一定要考虑不满足条件的那个区，把那个区定到最后！！！！还有设置配置文件时候一定要把这个区多留出来，比如这个分5个区，多一个不和条件区，所以一共分6个区"></a>需要注意的是 一定要考虑不满足条件的那个区，把那个区定到最后！！！！还有设置配置文件时候一定要把这个区多留出来，比如这个分5个区，多一个不和条件区，所以一共分6个区</h3><p>像这样</p>
<pre><code>job.setNumReduceTasks(6);
job.setPartitionerClass(那个Partition类的类名.class);
</code></pre>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-yarn与mr程序的那些事" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/13/yarn与mr程序的那些事/">yarn与mr程序的那些事</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/12/13/yarn与mr程序的那些事/" class="article-date">
  <time datetime="2017-12-13T01:10:00.000Z" itemprop="datePublished">2017-12-13</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="yarn是个运算（cpu、内存、程序和配置文件）资源调度的系统。"><a href="#yarn是个运算（cpu、内存、程序和配置文件）资源调度的系统。" class="headerlink" title="yarn是个运算（cpu、内存、程序和配置文件）资源调度的系统。"></a>yarn是个运算（cpu、内存、程序和配置文件）资源调度的系统。</h1><h2 id="说明："><a href="#说明：" class="headerlink" title="说明："></a>说明：</h2><h3 id="当mr程序放在yarn上运行时，相当于客户端提交到服务器进行运行以及数据处理，yarn只是个运行的平台，只负责程序所需-资源和内存-分配回收的调度工作，yarn与应用程序的内部运作无关，与mr框架低耦合的，spark也可以在上面运行。"><a href="#当mr程序放在yarn上运行时，相当于客户端提交到服务器进行运行以及数据处理，yarn只是个运行的平台，只负责程序所需-资源和内存-分配回收的调度工作，yarn与应用程序的内部运作无关，与mr框架低耦合的，spark也可以在上面运行。" class="headerlink" title="当mr程序放在yarn上运行时，相当于客户端提交到服务器进行运行以及数据处理，yarn只是个运行的平台，只负责程序所需 资源和内存 分配回收的调度工作，yarn与应用程序的内部运作无关，与mr框架低耦合的，spark也可以在上面运行。"></a>当mr程序放在yarn上运行时，相当于客户端提交到服务器进行运行以及数据处理，yarn只是个运行的平台，只负责程序所需 资源和内存 分配回收的调度工作，yarn与应用程序的内部运作无关，与mr框架低耦合的，spark也可以在上面运行。</h3><h3 id="yarn也是个集群结构，yarn的老大是resource-manager，其余是node-manager"><a href="#yarn也是个集群结构，yarn的老大是resource-manager，其余是node-manager" class="headerlink" title="yarn也是个集群结构，yarn的老大是resource manager，其余是node manager."></a>yarn也是个集群结构，yarn的老大是resource manager，其余是node manager.</h3><h3 id="nodemanager-里面的container：运行程序的箱子。yarn通过控制这些container从而实现分配内存和cpu调度。"><a href="#nodemanager-里面的container：运行程序的箱子。yarn通过控制这些container从而实现分配内存和cpu调度。" class="headerlink" title="nodemanager 里面的container：运行程序的箱子。yarn通过控制这些container从而实现分配内存和cpu调度。"></a>nodemanager 里面的container：运行程序的箱子。yarn通过控制这些container从而实现分配内存和cpu调度。</h3><h3 id="一个mr程序运行在yarn上的流程："><a href="#一个mr程序运行在yarn上的流程：" class="headerlink" title="一个mr程序运行在yarn上的流程："></a>一个mr程序运行在yarn上的流程：</h3><ol>
<li>当mr程序运行，它所在的节点提交运行（job.submit()），运行YarnRunner。yarnrunner先找resoucemanager（用过rpc远程调用）申请提交一个application </li>
<li>这时resourcemanger返回一个资源提交路径和jobid</li>
<li>yarnrunner接到路径和id后向hdfs提交资源文件 .staging/application_id </li>
<li>提交后yarnrunner向resourcemanager返回资源提交完毕，申请运行mrappmaster</li>
<li>此时resourcemanager执行一个FIFO调度策略的队列（Fair、capacity),同时把yarnrunner提交的信息和资源封装成一个task对象</li>
<li>nodemanger通过心跳感应和rpc调用，从resourcemanager那里领取一个task任务，</li>
<li>领取任务后后nodemanager生成容器——container（里面有cpu和内存），container从hdfs中下载所需运行资源，在容器里运行mrappmaster</li>
<li>mrappmaster向resourcemanager申请运行maptask运行内存和cpu的容器</li>
<li>resourcemangager接收到请求并向nodemanager发布创建容器任务</li>
<li>mrappmaster发送程序启动脚本</li>
<li>mrappmaster再向rm申请N个容器，用来运行reduceTask容器</li>
<li>reduce的容器向map的容器获取数据，在yarnchild中运行</li>
<li>全部运行完后mrappmaster向rm注销自己</li>
</ol>
<p>###几个小细节</p>
<ol>
<li>jobsubmit提交job资源路径时调用FileInputForamt.getSplits()获取切片规划到List<split>序列化成job.split。然后拷贝到.staging/application_id</split></li>
<li>jobsubmit把各种配置生成一个job.xml也拷贝到.staging/application_id</li>
<li>jobsumit最后获取Jar包来运行。。。。</li>
</ol>
<h2 id="额外内容：在windows里面本地运行mr程序的配置"><a href="#额外内容：在windows里面本地运行mr程序的配置" class="headerlink" title="额外内容：在windows里面本地运行mr程序的配置"></a>额外内容：在windows里面本地运行mr程序的配置</h2><p>需要在hadoop的依赖里面有winutil和hadoop.dll（hadoop.dll需要放在system32中），然后把hadoop文件夹和bin文件夹配到系统环境变量中</p>
<h2 id="在main程序中运行本地和集群需要给的参数："><a href="#在main程序中运行本地和集群需要给的参数：" class="headerlink" title="在main程序中运行本地和集群需要给的参数："></a>在main程序中运行本地和集群需要给的参数：</h2><h3 id="本地："><a href="#本地：" class="headerlink" title="本地："></a>本地：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">conf.set(&quot;mapreduce.framework.name&quot;,&quot;local&quot;)</div><div class="line">conf.set(&quot;fs.defaultFs&quot;,&quot;file:///&quot;)</div></pre></td></tr></table></figure>
<h3 id="集群"><a href="#集群" class="headerlink" title="集群:"></a>集群:</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">conf.set(&quot;mapreduce.framework.name&quot;,&quot;yarn&quot;)</div><div class="line">conf.set(&quot;yarn.resourcemanager.hostname&quot;,&quot;haihan&quot;)</div><div class="line">conf.set(&quot;fs.defaultFs&quot;,&quot;hdfs://haihan:9000/&quot;)</div></pre></td></tr></table></figure>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-关于MapReduce的所有个人理解" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/11/关于MapReduce的所有个人理解/">关于MapReduce的所有个人理解</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/12/11/关于MapReduce的所有个人理解/" class="article-date">
  <time datetime="2017-12-11T10:14:00.000Z" itemprop="datePublished">2017-12-11</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="MapReduce是一个框架，它将所写的逻辑和运算过程并发执行在hadoop集群上。"><a href="#MapReduce是一个框架，它将所写的逻辑和运算过程并发执行在hadoop集群上。" class="headerlink" title="MapReduce是一个框架，它将所写的逻辑和运算过程并发执行在hadoop集群上。"></a>MapReduce是一个框架，它将所写的逻辑和运算过程并发执行在hadoop集群上。</h1><h3 id="mr程序两个阶段，map（独立并发，文件切片，归类）reduce（汇聚，计算）"><a href="#mr程序两个阶段，map（独立并发，文件切片，归类）reduce（汇聚，计算）" class="headerlink" title="mr程序两个阶段，map（独立并发，文件切片，归类）reduce（汇聚，计算）"></a>mr程序两个阶段，map（独立并发，文件切片，归类）reduce（汇聚，计算）</h3><h3 id="运行mr程序有三个进程"><a href="#运行mr程序有三个进程" class="headerlink" title="运行mr程序有三个进程"></a>运行mr程序有三个进程</h3><ol>
<li>MRAppMaster：负责整个程序的过程调度及状态协调</li>
<li>mapTask：负责map阶段的数据处理流程</li>
<li>ReduceTask：负责reduce阶段的数据处理流程</li>
</ol>
<h2 id="mr程序运行第一步：文件切片"><a href="#mr程序运行第一步：文件切片" class="headerlink" title="mr程序运行第一步：文件切片"></a>mr程序运行第一步：文件切片</h2><p>文件的切片是由FileInputFormat实现类的getSplits()方法完成，先读取目录，然后遍历所有文件，获取文件大小fs.sizeOf(文件名),计算切片大小<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">computerSplitSize(Math.max(minSize.Math.max(maxSize.blocksize))=blocksize=128M</div></pre></td></tr></table></figure></p>
<p>blocksize 默认128M，hdfs一个文件的大小，mr程序为了防止不必要的网络传输问题，默认设置为和hdfs中的文件切片一样大</p>
<p>比如：</p>
<blockquote>
<p>有两个文件 gy.txt 大小为 200M haihan.txt 大小为8M </p>
</blockquote>
<p>切片后为</p>
<blockquote>
<p>gy.txt.split1 0~128M  gy.txt.split2 128M~200M haihan.txt.split 0~8M</p>
</blockquote>
<p>由此可见，小文件越多效率越低，注意上传文件时的合并或写一个小mr文件来合并、或者用Inputformat中的CombineInputFormat。</p>
<p>如果文件太大了，就把hdfs上的切片blocksize变大</p>
<blockquote>
<h4 id="设置reduce运行个数"><a href="#设置reduce运行个数" class="headerlink" title="设置reduce运行个数"></a>设置reduce运行个数</h4><p>job.setNumReduceTasks(4);</p>
</blockquote>
<p>如设置的数据分布不均匀，就有可能在reduce阶段产生数据倾斜（好多数据都跑一个reducetask里面了）<br>注意： reducetask数量并不是任意设置，还要考虑业务逻辑需求，有些情况下，需要计算全局汇总结果，就只能有1个reducetask</p>
<blockquote>
<p>尽量不要运行太多的reduce task。对大多数job来说，最好rduce的个数最多和集群中的reduce持平，或者比集群的 reduce slots小。这个对于小集群而言，尤其重要。</p>
</blockquote>
<p>运行后的maptask调用Inputformat （这货是个抽象类有好多实现 mr程序主要用 FileInputformat下的TextInputFormat（文本文件）和SequenceFileInpitFormat(））InputFormat调用RecordReader来读文件切切切，读好后传给map方法。</p>
<h2 id="mr程序运行第二步："><a href="#mr程序运行第二步：" class="headerlink" title="mr程序运行第二步："></a>mr程序运行第二步：</h2><p>调用map方法拿到kv对，运行map逻辑后（map逻辑是由自己瞎写的跟人家框架没关系），通过context.write写出到内部组件OutPutCollector（收集器~框架给的咱们动不了）</p>
<h2 id="mr程序运行第三步："><a href="#mr程序运行第三步：" class="headerlink" title="mr程序运行第三步："></a>mr程序运行第三步：</h2><p>OutPutCollector把自己瞎写的逻辑以及自己定义的输出 输出到一个环形缓冲区（这个内存一共默认100M，学名环形缓冲区内存，就是个环形数组队列！但只能写80%）<br>spiller这个东西负责把缓冲区分区并把数据排序并溢出到文件到内存中，排序用内存就是用剩下那个20%。</p>
<p>spiller这个分区就是Partitoner 默认为HashPartitioner （HashCode Mod 2）</p>
<p>排序则是快速排序KeycomparorTo，这里所有的排序都是以key来排序</p>
<p>比如：</p>
<blockquote>
<p>排序前：a1，c1，b1，a1，b1 排序后：（a1，a1，c1）（b1，b1）</p>
</blockquote>
<p>然后从内存写出来写到文件中（溢出一次写一次，产生一个文件，可能为多个文件）文件就在maptask工作目录里面，溢出的结果都是分区且区内有序的。<br>当最后一次溢出完，把剩下的没满的一次溢出。溢出后marge（归并）成一个大文件。</p>
<h3 id="效率提高大法：conbiner组件（预先reduce）"><a href="#效率提高大法：conbiner组件（预先reduce）" class="headerlink" title="效率提高大法：conbiner组件（预先reduce）"></a>效率提高大法：conbiner组件（预先reduce）</h3><p>为了防止在溢出reduce时过慢，conbiner组件可以在mapTask本地时将文件进行reduce 以及在合并文件后进行reduce<br>这个可以自定义！！！！！！</p>
<h2 id="mr程序运行第四步："><a href="#mr程序运行第四步：" class="headerlink" title="mr程序运行第四步："></a>mr程序运行第四步：</h2><p>说明：reduceTask的数量与spiller分的区没有直接关系，reduceTask的数量由我自己定的或框架默认。当然要想办法让它们对应起来</p>
<p>比如：</p>
<blockquote>
<p>key.hashCode % numreduce</p>
</blockquote>
<p>reduceTask下载mapTask归并的文件到reduceTask的机器本地磁盘目录，然后再次合并</p>
<p>比如：</p>
<blockquote>
<p>a1，a1，c1，b1，b1</p>
</blockquote>
<p>此时reducer中的reduce方法调用</p>
<h3 id="GroupingComparor（k，next-k）"><a href="#GroupingComparor（k，next-k）" class="headerlink" title="GroupingComparor（k，next k）"></a>GroupingComparor（k，next k）</h3><p>方法来判断谁和谁相同，可以自己定义文件中的k相同,传入k和v的迭代器，把所有相同的k合并成一个k，这个k带一组v<br>然后context.write()</p>
<h3 id="mr程序运行第五步："><a href="#mr程序运行第五步：" class="headerlink" title="mr程序运行第五步："></a>mr程序运行第五步：</h3><p>reduceTask调用OutputFormat中的TextOutputFormat，RecordWriter write（k，v）写到HDFS中，名字为part-1-000000</p>
<h2 id="shuffer就是输出到缓冲区开始一直到reducer调用reduce之前！"><a href="#shuffer就是输出到缓冲区开始一直到reducer调用reduce之前！" class="headerlink" title="shuffer就是输出到缓冲区开始一直到reducer调用reduce之前！"></a>shuffer就是输出到缓冲区开始一直到reducer调用reduce之前！</h2><p>听着很屌其实就是那么一回事</p>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-拯救笔记----流量汇总排序mr程序" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/12/11/拯救笔记----流量汇总排序mr程序/">拯救笔记----流量汇总排序mr程序</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/12/11/拯救笔记----流量汇总排序mr程序/" class="article-date">
  <time datetime="2017-12-11T03:45:00.000Z" itemprop="datePublished">2017-12-11</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="需求：对一段网络流量日志进行清洗，然后排序输出"><a href="#需求：对一段网络流量日志进行清洗，然后排序输出" class="headerlink" title="需求：对一段网络流量日志进行清洗，然后排序输出"></a>需求：对一段网络流量日志进行清洗，然后排序输出</h2><h3 id="map阶段"><a href="#map阶段" class="headerlink" title="map阶段"></a>map阶段</h3><pre><code>String line = value.toString();
String[] fields = line.split(&quot;\t&quot;);
long num =Long.parseLong(fields[1]);
long up = Long.parseLong(fields[fields.length-1]);
long down = Long.parseLong(fields[fields.length-2]);
IntWritable V = new IntWritable(1);
flowbean K = new flowbean(up, down,num);
context.write(K,V);
</code></pre><h3 id="超级垃圾无脑版本代码-就是切切切-然后构造一个bean"><a href="#超级垃圾无脑版本代码-就是切切切-然后构造一个bean" class="headerlink" title="超级垃圾无脑版本代码 就是切切切 然后构造一个bean"></a>超级垃圾无脑版本代码 就是切切切 然后构造一个bean</h3><h3 id="把上传流量和下载流量还有手机号传进去"><a href="#把上传流量和下载流量还有手机号传进去" class="headerlink" title="把上传流量和下载流量还有手机号传进去"></a>把上传流量和下载流量还有手机号传进去</h3><h3 id="实验了几次，发现map阶段不能传空值！new了一个-IntWritable-过去。"><a href="#实验了几次，发现map阶段不能传空值！new了一个-IntWritable-过去。" class="headerlink" title="实验了几次，发现map阶段不能传空值！new了一个 IntWritable 过去。"></a>实验了几次，发现map阶段不能传空值！new了一个 IntWritable 过去。</h3><h3 id="为了防止new的IntWritable对象太多，就传一个了。"><a href="#为了防止new的IntWritable对象太多，就传一个了。" class="headerlink" title="为了防止new的IntWritable对象太多，就传一个了。"></a>为了防止new的IntWritable对象太多，就传一个了。</h3><h4 id="内部过程"><a href="#内部过程" class="headerlink" title="内部过程"></a>内部过程</h4><p>flowbean,1</p>
<p>flowbean,1</p>
<p>flowbean,1</p>
<p>flowbean,1<br>每个flowbean对象都不等，不用担心到reduce阶段合并的问题。</p>
<h3 id="对于排序-在flowbean类中实现WritableComparable接口-然后重写compareTo方法，在compareTo里面写排序逻辑。"><a href="#对于排序-在flowbean类中实现WritableComparable接口-然后重写compareTo方法，在compareTo里面写排序逻辑。" class="headerlink" title="对于排序 在flowbean类中实现WritableComparable接口 然后重写compareTo方法，在compareTo里面写排序逻辑。"></a>对于排序 在flowbean类中实现WritableComparable<t>接口 然后重写compareTo方法，在compareTo里面写排序逻辑。</t></h3><h3 id="reduce阶段"><a href="#reduce阶段" class="headerlink" title="reduce阶段"></a>reduce阶段</h3><h4 id="直接无脑输出！"><a href="#直接无脑输出！" class="headerlink" title="直接无脑输出！"></a>直接无脑输出！</h4><pre><code>context.write(key, null);
</code></pre><h4 id="这次可以用空值搞定了！"><a href="#这次可以用空值搞定了！" class="headerlink" title="这次可以用空值搞定了！"></a>这次可以用空值搞定了！</h4><h2 id="出现的麻烦"><a href="#出现的麻烦" class="headerlink" title="出现的麻烦"></a>出现的麻烦</h2><h3 id="每次看结果里的num变量出不来！难道必须把电话号写出来才行？又仔细的回想了一遍过程，疯狂的google了一番"><a href="#每次看结果里的num变量出不来！难道必须把电话号写出来才行？又仔细的回想了一遍过程，疯狂的google了一番" class="headerlink" title="每次看结果里的num变量出不来！难道必须把电话号写出来才行？又仔细的回想了一遍过程，疯狂的google了一番"></a>每次看结果里的num变量出不来！难道必须把电话号写出来才行？又仔细的回想了一遍过程，疯狂的google了一番</h3><h3 id="最后发现flowbean中-Writable-的实现方法-write和readFields-方法中没把num变量写进去。尴尬的一b！"><a href="#最后发现flowbean中-Writable-的实现方法-write和readFields-方法中没把num变量写进去。尴尬的一b！" class="headerlink" title="最后发现flowbean中 Writable 的实现方法 write和readFields 方法中没把num变量写进去。尴尬的一b！"></a>最后发现flowbean中 Writable 的实现方法 write和readFields 方法中没把num变量写进去。尴尬的一b！</h3><h3 id="Ps：write和readFields-这俩方法中的变量必须按顺序写！"><a href="#Ps：write和readFields-这俩方法中的变量必须按顺序写！" class="headerlink" title="Ps：write和readFields 这俩方法中的变量必须按顺序写！"></a>Ps：write和readFields 这俩方法中的变量必须按顺序写！</h3>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-Linux安装hadoop前的配置" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/25/Linux安装hadoop前的配置/">Linux安装hadoop前的配置</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/09/25/Linux安装hadoop前的配置/" class="article-date">
  <time datetime="2017-09-25T15:22:00.000Z" itemprop="datePublished">2017-09-25</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="基本几步搞定linux配置"><a href="#基本几步搞定linux配置" class="headerlink" title="基本几步搞定linux配置"></a>基本几步搞定linux配置</h1><h2 id="自己看视频总结的。。"><a href="#自己看视频总结的。。" class="headerlink" title="自己看视频总结的。。"></a>自己看视频总结的。。</h2><p>在centos用minimal安装成功后..先干这几步</p>
<h2 id="1-修改网卡的基本配置"><a href="#1-修改网卡的基本配置" class="headerlink" title="1. 修改网卡的基本配置"></a>1. 修改网卡的基本配置</h2><h3 id="vi-etc-sysconfig-network-scripts-ifcfg-etho"><a href="#vi-etc-sysconfig-network-scripts-ifcfg-etho" class="headerlink" title="vi /etc/sysconfig/network-scripts/ifcfg-etho"></a>vi /etc/sysconfig/network-scripts/ifcfg-etho</h3><p>DEVICE=eth0 （网卡的物理位置）<br>ONBOOT=yes（默认加载项）<br>BOOTPROTO=static（设置成静态网卡）<br>IPADDR=设置的ip地址（不用解释了吧）</p>
<h2 id="2-修改网卡的全局配置"><a href="#2-修改网卡的全局配置" class="headerlink" title="2. 修改网卡的全局配置"></a>2. 修改网卡的全局配置</h2><h3 id="vi-etc-sysconfig-network"><a href="#vi-etc-sysconfig-network" class="headerlink" title="vi /etc/sysconfig/network"></a>vi /etc/sysconfig/network</h3><p>NETWORKING=yes<br>HOSTNAME=主机名（全局主机名，用于区分集群的机器，以及配置hosts）<br>GATEWAY=网关（网关地址，如果是虚拟机就看虚拟网络配置中的网关）</p>
<h2 id="3-删除克隆机相同的网卡（如果不是虚拟克隆机可以略过）"><a href="#3-删除克隆机相同的网卡（如果不是虚拟克隆机可以略过）" class="headerlink" title="3. 删除克隆机相同的网卡（如果不是虚拟克隆机可以略过）"></a>3. 删除克隆机相同的网卡（如果不是虚拟克隆机可以略过）</h2><h3 id="vi-etc-udev-rules-d-70-persistent-net-rules"><a href="#vi-etc-udev-rules-d-70-persistent-net-rules" class="headerlink" title="vi /etc/udev/rules.d/70-persistent-net.rules"></a>vi /etc/udev/rules.d/70-persistent-net.rules</h3><p>删除原eth0，把eth1改成eth0</p>
<h2 id="4-修改hosts文件（重要的一匹！！！！）"><a href="#4-修改hosts文件（重要的一匹！！！！）" class="headerlink" title="4. 修改hosts文件（重要的一匹！！！！）"></a>4. 修改hosts文件（重要的一匹！！！！）</h2><h3 id="vi-etc-hosts"><a href="#vi-etc-hosts" class="headerlink" title="vi /etc/hosts"></a>vi /etc/hosts</h3><p>格式： IP地址  域名</p>
<h2 id="5-（补充）当域名ping不通外网时候的解决办法"><a href="#5-（补充）当域名ping不通外网时候的解决办法" class="headerlink" title="5.（补充）当域名ping不通外网时候的解决办法"></a>5.（补充）当域名ping不通外网时候的解决办法</h2><h3 id="vi-etc-resolv-conf"><a href="#vi-etc-resolv-conf" class="headerlink" title="vi /etc/resolv.conf"></a>vi /etc/resolv.conf</h3><p>   设置DNS服务器<br>   nameserver 8.8.8.8<br>   nameserver 8.8.4.4</p>
<h2 id="6-给hadoop新建一个专属用户"><a href="#6-给hadoop新建一个专属用户" class="headerlink" title="6.给hadoop新建一个专属用户"></a>6.给hadoop新建一个专属用户</h2><h3 id="useradd-用户名-passwd-密码"><a href="#useradd-用户名-passwd-密码" class="headerlink" title="useradd 用户名 passwd 密码"></a>useradd 用户名 passwd 密码</h3><h2 id="7-简单两步配置ssh免密登陆"><a href="#7-简单两步配置ssh免密登陆" class="headerlink" title="7.简单两步配置ssh免密登陆"></a>7.简单两步配置ssh免密登陆</h2><h3 id="ssh-keygen（三下回车）"><a href="#ssh-keygen（三下回车）" class="headerlink" title="ssh-keygen（三下回车）"></a>ssh-keygen（三下回车）</h3><h3 id="ssh-copy-id-主机名（输入密码）"><a href="#ssh-copy-id-主机名（输入密码）" class="headerlink" title="ssh-copy-id 主机名（输入密码）"></a>ssh-copy-id 主机名（输入密码）</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">接下来就可以感受hadoop了</div></pre></td></tr></table></figure>
      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-关于JAVA的一些小记" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/25/关于JAVA的一些小记/">关于JAVA的一些小记</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/09/25/关于JAVA的一些小记/" class="article-date">
  <time datetime="2017-09-25T15:22:00.000Z" itemprop="datePublished">2017-09-25</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1-线程调用-run-和-start-的-区别"><a href="#1-线程调用-run-和-start-的-区别" class="headerlink" title="1.线程调用 run 和 start 的 区别"></a>1.线程调用 run 和 start 的 区别</h2><p>调用run方法，其本质就是一个普通方法的调用，不会开启新的线程。</p>
<p>调用start方法，才会开启一个线程来执行run里面的方法</p>
<h2 id="2-使用Thread和Runnable的区别"><a href="#2-使用Thread和Runnable的区别" class="headerlink" title="2.使用Thread和Runnable的区别"></a>2.使用Thread和Runnable的区别</h2><p>Thread：先继承Thread，然后通过new来实现类</p>
<p>Runnable：先继承Runnable，然后new Thread(new 实现类的对象,线程名)</p>

      

      
        
    </div>
  </div>
  
</article>



  
    <article id="post-正式安装hadoop" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2017/09/25/正式安装hadoop/">正式安装hadoop！！！</a>
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/2017/09/25/正式安装hadoop/" class="article-date">
  <time datetime="2017-09-25T15:22:00.000Z" itemprop="datePublished">2017-09-25</time>
</a>
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="正式安装hadoop！！！"><a href="#正式安装hadoop！！！" class="headerlink" title="正式安装hadoop！！！"></a>正式安装hadoop！！！</h1><p>在进行 tar 解压hadooptar包之后</p>
<h2 id="1-认识目录"><a href="#1-认识目录" class="headerlink" title="1. 认识目录"></a>1. 认识目录</h2><h3 id="bin"><a href="#bin" class="headerlink" title="bin/"></a>bin/</h3><p>hadoop自己的操作命令</p>
<p>###sbin/<br>启动集群的管理命令</p>
<p>###etc/<br>配置文件</p>
<p>###lib/<br>C语言的本地库</p>
<p>###include/<br>支持的C语言库</p>
<p>###share/<br>JAR包和文档</p>
<h2 id="2-开始配置"><a href="#2-开始配置" class="headerlink" title="2.开始配置"></a>2.开始配置</h2><p>###进入etc： cd hadoop的安装位置/etc/hadoop<br>参数格式(接下来统一用name：。。和value：。。来标注）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">&lt;name&gt;&lt;/name&gt;</div><div class="line">&lt;value&gt;&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<h4 id="配置hadoop-env-sh"><a href="#配置hadoop-env-sh" class="headerlink" title="配置hadoop-env.sh"></a>配置hadoop-env.sh</h4><p>这里主要是运行时所需要的环境变量主要也就是JAVA_HOME的位置</p>
<p> The java implementation to use<br> export JAVA_HOME=你的java安装位置 不知道就echo $JAVA_HOME</p>
<h4 id="配置core-site-xml"><a href="#配置core-site-xml" class="headerlink" title="配置core-site.xml"></a>配置core-site.xml</h4><ul>
<li><p>name:   fs.defaultFS</p>
</li>
<li><p>value:  hdfs://g1:9000</p>
</li>
</ul>
<p>说明:指定hadoop的文件系统以及namemode的地址</p>
<ul>
<li><p>name:   hadoop.tmp.dir</p>
</li>
<li><p>value:  /home/hadoop/hadoopdata</p>
</li>
</ul>
<p>说明:配置进程产生数据的路径（具体路径具体设置)</p>
<h4 id="配置hdfs-site-xml-也可以啥也不管，这个有默认设置-这里举两个例子省着忘）"><a href="#配置hdfs-site-xml-也可以啥也不管，这个有默认设置-这里举两个例子省着忘）" class="headerlink" title="配置hdfs-site.xml(也可以啥也不管，这个有默认设置.这里举两个例子省着忘）"></a>配置hdfs-site.xml(也可以啥也不管，这个有默认设置.这里举两个例子省着忘）</h4><p>例1</p>
<ul>
<li><p>name:   dfs.blocksize</p>
</li>
<li><p>value:  134217728(128MB)</p>
</li>
</ul>
<p>说明:文件拆分块的大小</p>
<p>例2</p>
<ul>
<li><p>name:   dfs.replication</p>
</li>
<li><p>value:  2</p>
</li>
</ul>
<p>说明:客户端放在hdfs的文件副本数(此处设置2份)</p>
<h4 id="配置mapred-site-xml"><a href="#配置mapred-site-xml" class="headerlink" title="配置mapred-site.xml"></a>配置mapred-site.xml</h4><ul>
<li><p>name:   mapreduce.framework.name</p>
</li>
<li><p>value:  yarn</p>
</li>
</ul>
<p>说明:mapreduce运行平台的配置，平台名称为local时是无集群单机版的hadoop</p>
<h4 id="配置yarn-site-xml"><a href="#配置yarn-site-xml" class="headerlink" title="配置yarn-site.xml"></a>配置yarn-site.xml</h4><ul>
<li><p>name:   yarn.resourcemanager.hostname</p>
</li>
<li><p>value:  g1   (主机名)</p>
</li>
</ul>
<p>说明:配置yarn的resourcemanager的机器</p>
<ul>
<li><p>name:   yarn.nodemanager.aux-services</p>
</li>
<li><p>value:  mapreduce_shuffle</p>
</li>
</ul>
<p>说明:reducer获取数据的方式</p>
<h4 id="最后配置slaves"><a href="#最后配置slaves" class="headerlink" title="最后配置slaves"></a>最后配置slaves</h4><p>此文件是启动脚本获取datanode地址的，在配置好/etc/hosts后，在此加入datanode就可以。直接写域名，不写IP地址</p>
<h1 id="启动之前"><a href="#启动之前" class="headerlink" title="启动之前"></a>启动之前</h1><p>··· </p>
<p>#一定一定一定要关闭防火墙！！重要！！！<br>···</p>
<h5 id="首先格式化HDFS：hadoop-namenode-format"><a href="#首先格式化HDFS：hadoop-namenode-format" class="headerlink" title="首先格式化HDFS：hadoop namenode -format"></a>首先格式化HDFS：hadoop namenode -format</h5><p>(使用这句话之前要配置hadoop的环境变量，在/etc/profile末尾写上<br>export HADOOP_HOME=/home/ghadoop/apps/hadoop-2.6.4<br>export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin)</p>
<h5 id="然后启动脚本-start-dfs-sh-只启动hdfs-start-all-sh-全部启动-或-hadoop-dameon-sh-start-namenode-只启动namenode的单个启动，把namenode换成datanode就是单个启动datanode"><a href="#然后启动脚本-start-dfs-sh-只启动hdfs-start-all-sh-全部启动-或-hadoop-dameon-sh-start-namenode-只启动namenode的单个启动，把namenode换成datanode就是单个启动datanode" class="headerlink" title="然后启动脚本 start-dfs.sh(只启动hdfs) start-all.sh(全部启动) 或 hadoop-dameon.sh start namenode(只启动namenode的单个启动，把namenode换成datanode就是单个启动datanode)"></a>然后启动脚本 start-dfs.sh(只启动hdfs) start-all.sh(全部启动) 或 hadoop-dameon.sh start namenode(只启动namenode的单个启动，把namenode换成datanode就是单个启动datanode)</h5>
      

      
        
    </div>
  </div>
  
</article>



  
  
</section>
        <aside id="sidebar">
  <nav class="menus">
  	<ul>
  		<li><a href="/"><i class="icon icon-home"></i></a></li>
  		
			<li><a href="/archives"><i class="icon icon-fenlei"></i></a></li>
  		
  		
			<li><a href="/tags"><i class="icon icon-tag"></i></a></li>
  		
  		
  			<li><a href="https://github.com/g5539220y" target="_blank"><i class="icon icon-github"></i></a></li>
  		
  	</ul>
  </nav>
  <a id="go-top" href="#"><i class="icon icon-up"></i></a>
</aside>

      </div>
      <footer id="footer">
  
	<div id="footer-info" class="inner">
	  &copy; 2017 圈 
	  - Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	  - Theme <a href="https://github.com/hejianxian/hexo-theme-jane/" target="_blank">Jane</a>
	</div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/tags" class="mobile-nav-link">Tag</a>
  
    <a href="https://github.com/g5539220y" class="mobile-nav-link">Github</a>
  
</nav>
    

<script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>